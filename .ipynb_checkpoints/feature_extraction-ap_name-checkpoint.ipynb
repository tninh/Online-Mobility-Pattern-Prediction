{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import defaultdict, Counter\n",
    "import datetime\n",
    "# import pykovy-master/ \n",
    "from pykovy.src.pykovy import chain\n",
    "import matplotlib.pyplot as plt\n",
    "from time import time\n",
    "import networkx as nx\n",
    "import math\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.python.keras.models import Sequential, Model\n",
    "from tensorflow.python.keras.layers import Dense, GRU, Embedding, LSTM, Flatten, Reshape, Input, BatchNormalization, Bidirectional\n",
    "from tensorflow.python.keras.optimizers import Adam\n",
    "# from tensorflow.python.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.python.keras.utils import to_categorical\n",
    "from tensorflow.python.keras.layers import add, concatenate\n",
    "\n",
    "\n",
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# np.random.seed(42)\n",
    "\n",
    "# model = hmm.GaussianHMM(n_components=3, covariance_type=\"full\")\n",
    "# model.startprob_ = np.array([0.6, 0.3, 0.1])\n",
    "# model.transmat_ = np.array([[0.7, 0.2, 0.1],\n",
    "#                             [0.3, 0.5, 0.2],\n",
    "#                             [0.3, 0.3, 0.4]])\n",
    "# model.means_ = np.array([[0.0, 0.0], [3.0, -3.0], [5.0, 10.0]])\n",
    "# model.covars_ = np.tile(np.identity(2), (3, 1, 1))\n",
    "# X, Z = model.sample(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv('../all_data.csv')\n",
    "# df = df[['Client Username', 'Association Time', 'Map Location', 'Session Duration']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# re-code userid\n",
    "# df['Client Username'] = pd.Categorical(df['Client Username'])\n",
    "# df['Client Username'] = df['Client Username'].cat.codes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../all_data.csv')\n",
    "df = df[['Client Username', 'Association Time', 'AP Name', 'Session Duration', 'Client MAC Address']]\n",
    "df = df.assign(id=(df['Client Username'] + '_' + df['Client MAC Address']).astype('category').cat.codes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['Client Username', 'Client MAC Address'], axis=1)\n",
    "df.rename(columns={'id':'Client Username'}, inplace=True)\n",
    "df = df[['Client Username', 'Association Time', 'AP Name', 'Session Duration']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# recode map location\n",
    "ap_dict = {}\n",
    "count = 0\n",
    "for i in df['AP Name'].unique():\n",
    "    ap_dict[i] = count\n",
    "    count += 1\n",
    "df['AP Name'] = df['AP Name'].map(ap_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Client Username</th>\n",
       "      <th>Association Time</th>\n",
       "      <th>AP Name</th>\n",
       "      <th>Session Duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29587</th>\n",
       "      <td>2</td>\n",
       "      <td>Sun Jul 01 18:40:53 PDT 2018</td>\n",
       "      <td>10</td>\n",
       "      <td>5 min 2 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29588</th>\n",
       "      <td>2</td>\n",
       "      <td>Sun Jul 01 19:06:24 PDT 2018</td>\n",
       "      <td>10</td>\n",
       "      <td>25 min 20 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404846</th>\n",
       "      <td>2</td>\n",
       "      <td>Tue Jun 19 14:45:33 PDT 2018</td>\n",
       "      <td>10</td>\n",
       "      <td>10 min 14 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404847</th>\n",
       "      <td>2</td>\n",
       "      <td>Tue Jun 19 14:55:48 PDT 2018</td>\n",
       "      <td>10</td>\n",
       "      <td>30 min 58 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404848</th>\n",
       "      <td>2</td>\n",
       "      <td>Tue Jun 19 15:26:47 PDT 2018</td>\n",
       "      <td>10</td>\n",
       "      <td>5 min 5 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>459131</th>\n",
       "      <td>2</td>\n",
       "      <td>Fri Jun 15 18:31:50 PDT 2018</td>\n",
       "      <td>10</td>\n",
       "      <td>1 hrs 2 min 9 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>459132</th>\n",
       "      <td>2</td>\n",
       "      <td>Sat Jun 16 08:15:43 PDT 2018</td>\n",
       "      <td>10</td>\n",
       "      <td>1 hrs 15 min 26 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>459133</th>\n",
       "      <td>2</td>\n",
       "      <td>Sat Jun 16 09:31:10 PDT 2018</td>\n",
       "      <td>10</td>\n",
       "      <td>5 min 1 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>459134</th>\n",
       "      <td>2</td>\n",
       "      <td>Sat Jun 16 09:41:14 PDT 2018</td>\n",
       "      <td>39</td>\n",
       "      <td>5 min 0 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>459135</th>\n",
       "      <td>2</td>\n",
       "      <td>Sat Jun 16 09:46:15 PDT 2018</td>\n",
       "      <td>39</td>\n",
       "      <td>20 min 14 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>895230</th>\n",
       "      <td>2</td>\n",
       "      <td>Mon Jun 11 11:01:15 PDT 2018</td>\n",
       "      <td>10</td>\n",
       "      <td>40 min 59 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>895231</th>\n",
       "      <td>2</td>\n",
       "      <td>Mon Jun 11 11:42:15 PDT 2018</td>\n",
       "      <td>10</td>\n",
       "      <td>5 min 8 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>895232</th>\n",
       "      <td>2</td>\n",
       "      <td>Mon Jun 11 11:47:24 PDT 2018</td>\n",
       "      <td>10</td>\n",
       "      <td>1 hrs 6 min 52 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1094385</th>\n",
       "      <td>2</td>\n",
       "      <td>Sat Jun 23 17:57:39 PDT 2018</td>\n",
       "      <td>10</td>\n",
       "      <td>40 min 42 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1094386</th>\n",
       "      <td>2</td>\n",
       "      <td>Sat Jun 23 18:43:26 PDT 2018</td>\n",
       "      <td>178</td>\n",
       "      <td>5 min 3 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1094387</th>\n",
       "      <td>2</td>\n",
       "      <td>Sat Jun 23 18:48:29 PDT 2018</td>\n",
       "      <td>10</td>\n",
       "      <td>10 min 6 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1094388</th>\n",
       "      <td>2</td>\n",
       "      <td>Sat Jun 23 18:58:36 PDT 2018</td>\n",
       "      <td>10</td>\n",
       "      <td>5 min 1 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1094389</th>\n",
       "      <td>2</td>\n",
       "      <td>Sat Jun 23 19:03:38 PDT 2018</td>\n",
       "      <td>178</td>\n",
       "      <td>5 min 1 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1094390</th>\n",
       "      <td>2</td>\n",
       "      <td>Sat Jun 23 19:23:50 PDT 2018</td>\n",
       "      <td>10</td>\n",
       "      <td>10 min 5 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1094391</th>\n",
       "      <td>2</td>\n",
       "      <td>Sat Jun 23 19:39:09 PDT 2018</td>\n",
       "      <td>10</td>\n",
       "      <td>25 min 53 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1094392</th>\n",
       "      <td>2</td>\n",
       "      <td>Sat Jun 23 20:10:14 PDT 2018</td>\n",
       "      <td>10</td>\n",
       "      <td>5 min 0 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1094393</th>\n",
       "      <td>2</td>\n",
       "      <td>Sat Jun 23 20:41:21 PDT 2018</td>\n",
       "      <td>10</td>\n",
       "      <td>10 min 13 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1472800</th>\n",
       "      <td>2</td>\n",
       "      <td>Thu Jun 21 21:28:27 PDT 2018</td>\n",
       "      <td>10</td>\n",
       "      <td>10 min 15 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1655137</th>\n",
       "      <td>2</td>\n",
       "      <td>Wed Jun 27 14:57:36 PDT 2018</td>\n",
       "      <td>10</td>\n",
       "      <td>5 min 12 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1655140</th>\n",
       "      <td>2</td>\n",
       "      <td>Wed Jun 27 14:52:21 PDT 2018</td>\n",
       "      <td>10</td>\n",
       "      <td>5 min 14 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1655141</th>\n",
       "      <td>2</td>\n",
       "      <td>Wed Jun 27 15:02:49 PDT 2018</td>\n",
       "      <td>10</td>\n",
       "      <td>5 min 12 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1655142</th>\n",
       "      <td>2</td>\n",
       "      <td>Wed Jun 27 15:08:02 PDT 2018</td>\n",
       "      <td>10</td>\n",
       "      <td>15 min 24 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1655143</th>\n",
       "      <td>2</td>\n",
       "      <td>Wed Jun 27 15:28:43 PDT 2018</td>\n",
       "      <td>193</td>\n",
       "      <td>5 min 7 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1655144</th>\n",
       "      <td>2</td>\n",
       "      <td>Wed Jun 27 15:33:50 PDT 2018</td>\n",
       "      <td>178</td>\n",
       "      <td>5 min 14 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1655145</th>\n",
       "      <td>2</td>\n",
       "      <td>Wed Jun 27 15:39:05 PDT 2018</td>\n",
       "      <td>10</td>\n",
       "      <td>15 min 28 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4139926</th>\n",
       "      <td>2</td>\n",
       "      <td>Wed Jul 11 15:43:27 PDT 2018</td>\n",
       "      <td>10</td>\n",
       "      <td>10 min 14 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4358336</th>\n",
       "      <td>2</td>\n",
       "      <td>Wed Jun 13 13:39:46 PDT 2018</td>\n",
       "      <td>10</td>\n",
       "      <td>25 min 42 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4407828</th>\n",
       "      <td>2</td>\n",
       "      <td>Sat Jun 16 20:12:04 PDT 2018</td>\n",
       "      <td>10</td>\n",
       "      <td>35 min 21 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4407829</th>\n",
       "      <td>2</td>\n",
       "      <td>Sat Jun 16 20:47:26 PDT 2018</td>\n",
       "      <td>178</td>\n",
       "      <td>10 min 13 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5013097</th>\n",
       "      <td>2</td>\n",
       "      <td>Tue Jul 03 21:03:11 PDT 2018</td>\n",
       "      <td>10</td>\n",
       "      <td>10 min 8 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5013098</th>\n",
       "      <td>2</td>\n",
       "      <td>Wed Jul 04 11:07:18 PDT 2018</td>\n",
       "      <td>10</td>\n",
       "      <td>20 min 51 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5013099</th>\n",
       "      <td>2</td>\n",
       "      <td>Wed Jul 04 14:16:03 PDT 2018</td>\n",
       "      <td>10</td>\n",
       "      <td>5 min 2 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5013100</th>\n",
       "      <td>2</td>\n",
       "      <td>Wed Jul 04 14:26:07 PDT 2018</td>\n",
       "      <td>10</td>\n",
       "      <td>10 min 4 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5013101</th>\n",
       "      <td>2</td>\n",
       "      <td>Wed Jul 04 14:36:11 PDT 2018</td>\n",
       "      <td>10</td>\n",
       "      <td>15 min 6 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5013102</th>\n",
       "      <td>2</td>\n",
       "      <td>Wed Jul 04 14:56:21 PDT 2018</td>\n",
       "      <td>10</td>\n",
       "      <td>30 min 48 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5013103</th>\n",
       "      <td>2</td>\n",
       "      <td>Wed Jul 04 15:58:52 PDT 2018</td>\n",
       "      <td>83</td>\n",
       "      <td>5 min 1 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5013104</th>\n",
       "      <td>2</td>\n",
       "      <td>Wed Jul 04 16:04:03 PDT 2018</td>\n",
       "      <td>10</td>\n",
       "      <td>9 min 37 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5073761</th>\n",
       "      <td>2</td>\n",
       "      <td>Thu Jul 12 13:22:47 PDT 2018</td>\n",
       "      <td>48</td>\n",
       "      <td>5 min 29 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5162134</th>\n",
       "      <td>2</td>\n",
       "      <td>Wed Jun 20 17:40:03 PDT 2018</td>\n",
       "      <td>10</td>\n",
       "      <td>5 min 7 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5162135</th>\n",
       "      <td>2</td>\n",
       "      <td>Wed Jun 20 17:50:15 PDT 2018</td>\n",
       "      <td>10</td>\n",
       "      <td>20 min 18 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5162136</th>\n",
       "      <td>2</td>\n",
       "      <td>Wed Jun 20 18:10:34 PDT 2018</td>\n",
       "      <td>10</td>\n",
       "      <td>5 min 2 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5162137</th>\n",
       "      <td>2</td>\n",
       "      <td>Wed Jun 20 18:15:36 PDT 2018</td>\n",
       "      <td>178</td>\n",
       "      <td>5 min 10 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5162138</th>\n",
       "      <td>2</td>\n",
       "      <td>Wed Jun 20 18:39:49 PDT 2018</td>\n",
       "      <td>10</td>\n",
       "      <td>10 min 20 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5162139</th>\n",
       "      <td>2</td>\n",
       "      <td>Thu Jun 21 11:06:08 PDT 2018</td>\n",
       "      <td>0</td>\n",
       "      <td>20 min 37 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5162140</th>\n",
       "      <td>2</td>\n",
       "      <td>Wed Jun 20 19:10:45 PDT 2018</td>\n",
       "      <td>10</td>\n",
       "      <td>20 min 37 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5162141</th>\n",
       "      <td>2</td>\n",
       "      <td>Wed Jun 20 19:52:15 PDT 2018</td>\n",
       "      <td>10</td>\n",
       "      <td>10 min 12 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5162142</th>\n",
       "      <td>2</td>\n",
       "      <td>Thu Jun 21 10:34:41 PDT 2018</td>\n",
       "      <td>10</td>\n",
       "      <td>21 min 6 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5162143</th>\n",
       "      <td>2</td>\n",
       "      <td>Thu Jun 21 12:02:54 PDT 2018</td>\n",
       "      <td>0</td>\n",
       "      <td>41 min 28 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5162144</th>\n",
       "      <td>2</td>\n",
       "      <td>Thu Jun 21 12:44:23 PDT 2018</td>\n",
       "      <td>1312</td>\n",
       "      <td>5 min 10 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5162145</th>\n",
       "      <td>2</td>\n",
       "      <td>Thu Jun 21 12:49:34 PDT 2018</td>\n",
       "      <td>11</td>\n",
       "      <td>5 min 6 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5162146</th>\n",
       "      <td>2</td>\n",
       "      <td>Thu Jun 21 12:54:45 PDT 2018</td>\n",
       "      <td>10</td>\n",
       "      <td>5 min 2 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5502536</th>\n",
       "      <td>2</td>\n",
       "      <td>Tue Jul 03 13:06:13 PDT 2018</td>\n",
       "      <td>10</td>\n",
       "      <td>21 min 23 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5502538</th>\n",
       "      <td>2</td>\n",
       "      <td>Mon Jul 02 20:26:20 PDT 2018</td>\n",
       "      <td>10</td>\n",
       "      <td>52 min 11 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5502539</th>\n",
       "      <td>2</td>\n",
       "      <td>Mon Jul 02 21:18:32 PDT 2018</td>\n",
       "      <td>178</td>\n",
       "      <td>5 min 3 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5502540</th>\n",
       "      <td>2</td>\n",
       "      <td>Tue Jul 03 13:27:36 PDT 2018</td>\n",
       "      <td>10</td>\n",
       "      <td>2 hrs 41 min 43 sec</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>86 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Client Username              Association Time  AP Name  \\\n",
       "29587                  2  Sun Jul 01 18:40:53 PDT 2018       10   \n",
       "29588                  2  Sun Jul 01 19:06:24 PDT 2018       10   \n",
       "404846                 2  Tue Jun 19 14:45:33 PDT 2018       10   \n",
       "404847                 2  Tue Jun 19 14:55:48 PDT 2018       10   \n",
       "404848                 2  Tue Jun 19 15:26:47 PDT 2018       10   \n",
       "459131                 2  Fri Jun 15 18:31:50 PDT 2018       10   \n",
       "459132                 2  Sat Jun 16 08:15:43 PDT 2018       10   \n",
       "459133                 2  Sat Jun 16 09:31:10 PDT 2018       10   \n",
       "459134                 2  Sat Jun 16 09:41:14 PDT 2018       39   \n",
       "459135                 2  Sat Jun 16 09:46:15 PDT 2018       39   \n",
       "895230                 2  Mon Jun 11 11:01:15 PDT 2018       10   \n",
       "895231                 2  Mon Jun 11 11:42:15 PDT 2018       10   \n",
       "895232                 2  Mon Jun 11 11:47:24 PDT 2018       10   \n",
       "1094385                2  Sat Jun 23 17:57:39 PDT 2018       10   \n",
       "1094386                2  Sat Jun 23 18:43:26 PDT 2018      178   \n",
       "1094387                2  Sat Jun 23 18:48:29 PDT 2018       10   \n",
       "1094388                2  Sat Jun 23 18:58:36 PDT 2018       10   \n",
       "1094389                2  Sat Jun 23 19:03:38 PDT 2018      178   \n",
       "1094390                2  Sat Jun 23 19:23:50 PDT 2018       10   \n",
       "1094391                2  Sat Jun 23 19:39:09 PDT 2018       10   \n",
       "1094392                2  Sat Jun 23 20:10:14 PDT 2018       10   \n",
       "1094393                2  Sat Jun 23 20:41:21 PDT 2018       10   \n",
       "1472800                2  Thu Jun 21 21:28:27 PDT 2018       10   \n",
       "1655137                2  Wed Jun 27 14:57:36 PDT 2018       10   \n",
       "1655140                2  Wed Jun 27 14:52:21 PDT 2018       10   \n",
       "1655141                2  Wed Jun 27 15:02:49 PDT 2018       10   \n",
       "1655142                2  Wed Jun 27 15:08:02 PDT 2018       10   \n",
       "1655143                2  Wed Jun 27 15:28:43 PDT 2018      193   \n",
       "1655144                2  Wed Jun 27 15:33:50 PDT 2018      178   \n",
       "1655145                2  Wed Jun 27 15:39:05 PDT 2018       10   \n",
       "...                  ...                           ...      ...   \n",
       "4139926                2  Wed Jul 11 15:43:27 PDT 2018       10   \n",
       "4358336                2  Wed Jun 13 13:39:46 PDT 2018       10   \n",
       "4407828                2  Sat Jun 16 20:12:04 PDT 2018       10   \n",
       "4407829                2  Sat Jun 16 20:47:26 PDT 2018      178   \n",
       "5013097                2  Tue Jul 03 21:03:11 PDT 2018       10   \n",
       "5013098                2  Wed Jul 04 11:07:18 PDT 2018       10   \n",
       "5013099                2  Wed Jul 04 14:16:03 PDT 2018       10   \n",
       "5013100                2  Wed Jul 04 14:26:07 PDT 2018       10   \n",
       "5013101                2  Wed Jul 04 14:36:11 PDT 2018       10   \n",
       "5013102                2  Wed Jul 04 14:56:21 PDT 2018       10   \n",
       "5013103                2  Wed Jul 04 15:58:52 PDT 2018       83   \n",
       "5013104                2  Wed Jul 04 16:04:03 PDT 2018       10   \n",
       "5073761                2  Thu Jul 12 13:22:47 PDT 2018       48   \n",
       "5162134                2  Wed Jun 20 17:40:03 PDT 2018       10   \n",
       "5162135                2  Wed Jun 20 17:50:15 PDT 2018       10   \n",
       "5162136                2  Wed Jun 20 18:10:34 PDT 2018       10   \n",
       "5162137                2  Wed Jun 20 18:15:36 PDT 2018      178   \n",
       "5162138                2  Wed Jun 20 18:39:49 PDT 2018       10   \n",
       "5162139                2  Thu Jun 21 11:06:08 PDT 2018        0   \n",
       "5162140                2  Wed Jun 20 19:10:45 PDT 2018       10   \n",
       "5162141                2  Wed Jun 20 19:52:15 PDT 2018       10   \n",
       "5162142                2  Thu Jun 21 10:34:41 PDT 2018       10   \n",
       "5162143                2  Thu Jun 21 12:02:54 PDT 2018        0   \n",
       "5162144                2  Thu Jun 21 12:44:23 PDT 2018     1312   \n",
       "5162145                2  Thu Jun 21 12:49:34 PDT 2018       11   \n",
       "5162146                2  Thu Jun 21 12:54:45 PDT 2018       10   \n",
       "5502536                2  Tue Jul 03 13:06:13 PDT 2018       10   \n",
       "5502538                2  Mon Jul 02 20:26:20 PDT 2018       10   \n",
       "5502539                2  Mon Jul 02 21:18:32 PDT 2018      178   \n",
       "5502540                2  Tue Jul 03 13:27:36 PDT 2018       10   \n",
       "\n",
       "            Session Duration  \n",
       "29587            5 min 2 sec  \n",
       "29588          25 min 20 sec  \n",
       "404846         10 min 14 sec  \n",
       "404847         30 min 58 sec  \n",
       "404848           5 min 5 sec  \n",
       "459131     1 hrs 2 min 9 sec  \n",
       "459132   1 hrs 15 min 26 sec  \n",
       "459133           5 min 1 sec  \n",
       "459134           5 min 0 sec  \n",
       "459135         20 min 14 sec  \n",
       "895230         40 min 59 sec  \n",
       "895231           5 min 8 sec  \n",
       "895232    1 hrs 6 min 52 sec  \n",
       "1094385        40 min 42 sec  \n",
       "1094386          5 min 3 sec  \n",
       "1094387         10 min 6 sec  \n",
       "1094388          5 min 1 sec  \n",
       "1094389          5 min 1 sec  \n",
       "1094390         10 min 5 sec  \n",
       "1094391        25 min 53 sec  \n",
       "1094392          5 min 0 sec  \n",
       "1094393        10 min 13 sec  \n",
       "1472800        10 min 15 sec  \n",
       "1655137         5 min 12 sec  \n",
       "1655140         5 min 14 sec  \n",
       "1655141         5 min 12 sec  \n",
       "1655142        15 min 24 sec  \n",
       "1655143          5 min 7 sec  \n",
       "1655144         5 min 14 sec  \n",
       "1655145        15 min 28 sec  \n",
       "...                      ...  \n",
       "4139926        10 min 14 sec  \n",
       "4358336        25 min 42 sec  \n",
       "4407828        35 min 21 sec  \n",
       "4407829        10 min 13 sec  \n",
       "5013097         10 min 8 sec  \n",
       "5013098        20 min 51 sec  \n",
       "5013099          5 min 2 sec  \n",
       "5013100         10 min 4 sec  \n",
       "5013101         15 min 6 sec  \n",
       "5013102        30 min 48 sec  \n",
       "5013103          5 min 1 sec  \n",
       "5013104         9 min 37 sec  \n",
       "5073761         5 min 29 sec  \n",
       "5162134          5 min 7 sec  \n",
       "5162135        20 min 18 sec  \n",
       "5162136          5 min 2 sec  \n",
       "5162137         5 min 10 sec  \n",
       "5162138        10 min 20 sec  \n",
       "5162139        20 min 37 sec  \n",
       "5162140        20 min 37 sec  \n",
       "5162141        10 min 12 sec  \n",
       "5162142         21 min 6 sec  \n",
       "5162143        41 min 28 sec  \n",
       "5162144         5 min 10 sec  \n",
       "5162145          5 min 6 sec  \n",
       "5162146          5 min 2 sec  \n",
       "5502536        21 min 23 sec  \n",
       "5502538        52 min 11 sec  \n",
       "5502539          5 min 3 sec  \n",
       "5502540  2 hrs 41 min 43 sec  \n",
       "\n",
       "[86 rows x 4 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['Client Username']==2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def timer(func):\n",
    "    # this part is for timer ignore\n",
    "    def wrapper(*arg):\n",
    "        before = time()\n",
    "        rv = func(*arg)\n",
    "        after = time()\n",
    "        print('Elapsed: ', after-before)\n",
    "        return rv\n",
    "    return wrapper\n",
    "\n",
    "def convertMonth(month):\n",
    "    if month == 'Jan': return 1\n",
    "    elif month == 'Feb': return 2\n",
    "    elif month == 'Mar': return 3\n",
    "    elif month == 'Apr': return 4\n",
    "    elif month == 'May': return 5\n",
    "    elif month == 'Jun': return 6\n",
    "    elif month == 'Jul': return 7\n",
    "    elif month == 'Aug': return 8\n",
    "    elif month == 'Sep': return 9\n",
    "    elif month == 'Oct': return 10\n",
    "    elif month == 'Nov': return 11\n",
    "    elif month == 'Dec': return 12\n",
    "    else: print('error input is not correct')\n",
    "        \n",
    "def convert_to_timeslot(duration):\n",
    "    temp = duration.split()\n",
    "    if len(temp) == 2: sess_duration = int(temp[0])\n",
    "    elif len(temp) == 4: sess_duration = int(temp[0]) * 60 + int(temp[2])\n",
    "    elif len(temp) == 6: sess_duration = (int(temp[0]) * 60 + int(temp[2])) * 60 + int(temp[4])\n",
    "    else: print('error')\n",
    "    return datetime.timedelta(seconds=sess_duration)\n",
    "\n",
    "def convert_to_datetime(time):\n",
    "    temp = time.split()\n",
    "    d_time = datetime.datetime(year=int(temp[5]), month=convertMonth(temp[1]), day=int(temp[2]), hour=int(temp[3].split(':')[0]), minute=int(temp[3].split(':')[1]), second=int(temp[3].split(':')[2]))\n",
    "    return d_time\n",
    "\n",
    "# data_list has same number of row as df.\n",
    "# Each row [userid, map_loc, associate_time, associate_time+sess_dur, sess_dur].\n",
    "def create_data_list(df):\n",
    "    np_df = df.values\n",
    "    data_list = []\n",
    "    c=0\n",
    "    for i in range(np_df.shape[0]):\n",
    "        if c%500000 == 0:\n",
    "            print(c)\n",
    "        temp = np_df[i]\n",
    "#         sess = convert_to_timeslot(df.iloc[i,3])\n",
    "#         s_time = convert_to_datetime(df.iloc[i,1])\n",
    "#         e_time = s_time + sess\n",
    "#         data_list.append([df.iloc[i,0], df.iloc[i,2], s_time, e_time, sess])\n",
    "        sess = convert_to_timeslot(temp[3])\n",
    "        s_time = convert_to_datetime(temp[1])\n",
    "        e_time = s_time + sess\n",
    "        data_list.append([temp[0], temp[2], s_time, e_time, sess])\n",
    "        c+=1\n",
    "        \n",
    "    data_list = sorted(data_list, key=lambda element: (element[0], element[2]))\n",
    "    data_list1 = sorted(data_list, key=lambda element: (element[2]))\n",
    "    first = data_list1[0][2]\n",
    "    last = data_list1[-1][2]\n",
    "    return data_list, first, last\n",
    "\n",
    "# add up the session duration when the previous row has the same userid and location. \n",
    "# (this happen when you disconnect from the ap and reconnect again or your wifi session expire, etc.)\n",
    "def preprocess_data_list(data_list):\n",
    "    for i in reversed(range(1, len(data_list))):\n",
    "        ts_cur = data_list[i][2]\n",
    "        ts_prev = data_list[i-1][2]\n",
    "        if data_list[i][0] == data_list[i-1][0] and data_list[i][1] == data_list[i-1][1] and ts_cur.day == ts_prev.day and ts_cur.month == ts_prev.month:\n",
    "#             if data_list[i][2] - data_list[i-1][3] <= datetime.timedelta(hours=2):\n",
    "            data_list[i-1][4] += data_list[i][4]\n",
    "#             else: print(i)\n",
    "    # loop each row, remove the next concecutive rows has the same userid and map_loc with the current row.\n",
    "    # Because they are useless now\n",
    "    final_data_list = []\n",
    "    i = 0\n",
    "    while i < len(data_list)-1:\n",
    "        ts_cur = data_list[i][2]\n",
    "        ts_next = data_list[i+1][2]\n",
    "        if data_list[i][0] == data_list[i+1][0] and data_list[i][1] == data_list[i+1][1] and ts_cur.day == ts_next.day and ts_cur.month == ts_next.month:\n",
    "            final_data_list.append(data_list[i])\n",
    "            c = 2\n",
    "            while i+c < len(data_list) and data_list[i][0] == data_list[i+c][0] and data_list[i][1] == data_list[i+c][1] and ts_cur.day == ts_next.day and ts_cur.month == ts_next.month:\n",
    "                c += 1\n",
    "            i += c\n",
    "\n",
    "        else:\n",
    "            final_data_list.append(data_list[i])\n",
    "            i += 1\n",
    "\n",
    "    if not (final_data_list[-1][0] == data_list[-1][0] and final_data_list[-1][1] == data_list[-1][1]):\n",
    "        final_data_list.append(data_list[-1])\n",
    "\n",
    "    return final_data_list\n",
    "\n",
    "\n",
    "# user_dict's key are each userid and value is a list of all rows of each user in final_data_list\n",
    "def create_user_dict(final_data_list):\n",
    "    user_dict = defaultdict(list)\n",
    "    for row in final_data_list:\n",
    "        user_dict[row[0]].append([row[2], row[1], row[4]])\n",
    "\n",
    "    return user_dict\n",
    "\n",
    "# \n",
    "def remove_jitter(final_data_list):\n",
    "    res = [final_data_list[0]]\n",
    "    i = 1\n",
    "    mem = 0\n",
    "    while i < len(final_data_list):\n",
    "        cur_usrid = final_data_list[i][0]\n",
    "        cur_loc = final_data_list[i][1]\n",
    "        cur_sess = final_data_list[i][4]\n",
    "        cur_end_time = final_data_list[i][2] + final_data_list[i][4]\n",
    "        cont_time = final_data_list[i][2] - (res[-1][2] + res[-1][4]) <= datetime.timedelta(minutes=1)\n",
    "        if cur_usrid == res[-1][0] and cur_sess <= datetime.timedelta(minutes=1) and cont_time:\n",
    "\n",
    "\n",
    "            if cur_loc != res[-1][1] and mem == 0:\n",
    "                mem = i\n",
    "\n",
    "            elif cur_loc == res[-1][1]:\n",
    "                \n",
    "#                 print(i, cur_loc, cur_end_time, res[-1][1], res[-1][2])\n",
    "\n",
    "#                 print(cur_end_time - res[-1][2])\n",
    "                res[-1][4] = cur_end_time - res[-1][2]\n",
    "#                 print(res[-1][4])\n",
    "                mem=0\n",
    "                \n",
    "            else: pass\n",
    "        elif cur_usrid == res[-1][0] and cur_sess <= datetime.timedelta(minutes=1) and not cont_time:\n",
    "            if cur_loc != res[-1][1] and mem == 0:\n",
    "                res.append(final_data_list[i])\n",
    "\n",
    "            elif cur_loc == res[-1][1]:\n",
    "                res[-1][4] = cur_end_time - res[-1][2]\n",
    "                mem=0\n",
    "                \n",
    "            else:                 \n",
    "                for j in range(mem, i):\n",
    "                    res.append(final_data_list[j])\n",
    "                res.append(final_data_list[i])\n",
    "                mem=0\n",
    "        else:\n",
    "            if mem != 0:\n",
    "                for j in range(mem, i):\n",
    "                    res.append(final_data_list[j])\n",
    "                res.append(final_data_list[i])\n",
    "                mem=0\n",
    "            else: res.append(final_data_list[i])\n",
    "        \n",
    "        i+=1\n",
    "\n",
    "    return res\n",
    "\n",
    "@timer\n",
    "def preprocess_and_create_user_dict(df):\n",
    "    data_list, start_ts, end_ts= create_data_list(df)\n",
    "    final_data_list = preprocess_data_list(data_list)\n",
    "    print(len(final_data_list), len(data_list))\n",
    "    final_data_list = remove_jitter(final_data_list)\n",
    "    print(len(final_data_list), len(data_list))\n",
    "    user_dict = create_user_dict(final_data_list)\n",
    "    return user_dict, start_ts, end_ts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "500000\n",
      "1000000\n",
      "1500000\n",
      "2000000\n",
      "2500000\n",
      "3000000\n",
      "3500000\n",
      "4000000\n",
      "4500000\n",
      "5000000\n",
      "5500000\n",
      "6000000\n",
      "4061485 6114987\n",
      "4061202 6114987\n",
      "Elapsed:  113.43636703491211\n"
     ]
    }
   ],
   "source": [
    "user_dict, start_ts, end_ts = preprocess_and_create_user_dict(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # make an 198x198 graph (198 is the number of aps) this is the graph of the school, \n",
    "# # the edges are how many connections in total that all students have traveled.\n",
    "# def create_198_198_map(df, user_dict, draw=True):\n",
    "#     num_aps = len(df[\"Map Location\"].unique())\n",
    "#     undir_map = np.zeros(39204, dtype=np.int32).reshape(198, 198)\n",
    "#     for usr in user_dict:\n",
    "#         for i in range(len(user_dict[usr])-1):\n",
    "#             if user_dict[usr][i][1] != user_dict[usr][i+1][1]:\n",
    "#                 undir_map[user_dict[usr][i][1]][user_dict[usr][i+1][1]] += 1\n",
    "#                 undir_map[user_dict[usr][i+1][1]][user_dict[usr][i][1]] += 1\n",
    "\n",
    "    \n",
    "#     # draw the number of connections each edge is used. Change ax.set_ylim([0, 75]) to scale the graph\n",
    "#     # try to find the edges that are bad (low connections, too high connections) and prune them\n",
    "#     if draw:\n",
    "#         draw_list = []\n",
    "#         c = 0\n",
    "#         for i in range(len(undir_map)):\n",
    "#             c+=1\n",
    "#             for j in range(len(undir_map[i])-c):\n",
    "#                 draw_list.append(undir_map[i][j+c])\n",
    "#         draw_list.sort()\n",
    "#         # Data for plotting\n",
    "#         x = np.arange(0,len(draw_list))\n",
    "\n",
    "#         _, ax = plt.subplots()\n",
    "#         ax.set_xlim([18500, len(draw_list)])\n",
    "#         ax.set_ylim([0, 9999])\n",
    "#         ax.plot(x, draw_list)\n",
    "#         ax.set(xlabel='number of edges', ylabel='number of connections',\n",
    "#                title='ap graph edge distribution')\n",
    "#         ax.grid()\n",
    "#         # fig.savefig(\"test.png\")\n",
    "#         plt.show()\n",
    "    \n",
    "#     return undir_map\n",
    "\n",
    "# undir_map = create_198_198_map(df, user_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def map_pruning(undir_map, low=50, high=5000):\n",
    "#     size = len(undir_map)\n",
    "#     undir_map1 = np.zeros(size**2, dtype=np.int32).reshape(size, size)\n",
    "\n",
    "#     for i in range(size):\n",
    "#         for j in range(size):\n",
    "#             if undir_map[i][j] >=low and undir_map[i][j] <=high:\n",
    "#                 undir_map1[i][j] = 1\n",
    "#             else: undir_map1[i][j] = 0\n",
    "\n",
    "#     return undir_map1\n",
    "\n",
    "# undir_map_prune = map_pruning(undir_map, low=50, high=5000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def create_nx_graph(undir_map_prune):\n",
    "#     nx_graph = nx.to_networkx_graph(undir_map_prune)\n",
    "#     res = np.arange(100, 110)\n",
    "#     # nx.draw_networkx(nx_graph, nodelist=res, node_size=[6])\n",
    "#     # pos = nx.spring_layout(nx_graph)  #setting the positions with respect to G, not k.\n",
    "#     k = nx_graph.subgraph(res)\n",
    "\n",
    "#     nx.draw_networkx(k)\n",
    "#     return nx_graph\n",
    "\n",
    "# nx_graph = create_nx_graph(undir_map_prune)\n",
    "\n",
    "# # find all the paths from 2 nodes with length of 3 or less\n",
    "# def find_all_paths(graph, src, dest, cutoff=3):\n",
    "#     paths = nx.algorithms.simple_paths.all_simple_paths(graph, src, dest, cutoff= cutoff)\n",
    "#     return paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_freq_dict(user_dict):\n",
    "    # time spend on each ap during the entire dataset for each user\n",
    "    ap_freq_dict = defaultdict(dict)\n",
    "    total_time_each_usr = {}\n",
    "    for usr in user_dict:\n",
    "        for i in range(len(user_dict[usr])): \n",
    "            ap_freq_dict[usr][user_dict[usr][i][1]] = datetime.timedelta(0)\n",
    "            total_time_each_usr[usr] = datetime.timedelta(0)\n",
    "\n",
    "    for usr in user_dict:\n",
    "        for i in range(len(user_dict[usr])):\n",
    "            ap_freq_dict[usr][user_dict[usr][i][1]] += user_dict[usr][i][2]\n",
    "            total_time_each_usr[usr] += user_dict[usr][i][2]\n",
    "    \n",
    "    return ap_freq_dict, total_time_each_usr\n",
    "\n",
    "ap_freq_dict, total_time_each_usr = create_freq_dict(user_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ap_freq_dict[787]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAT0AAAEnCAYAAADb1pRgAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\noiQUlfQURUkoKukpipJQ/h8dfemPEvaTYgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def draw_ap_freq(ap_freq_dict, total_time_each_usr, uID, draw_graph=False):\n",
    "    value_list = []\n",
    "    ap_list = []\n",
    "    total_time = total_time_each_usr[uID].total_seconds()\n",
    "    less_1 = 0\n",
    "    between_1_5 = 0\n",
    "    for ap in ap_freq_dict[uID]:\n",
    "        percentage = (ap_freq_dict[uID][ap].total_seconds()/total_time)*100\n",
    "        if percentage >= 5.0:\n",
    "            ap_list.append(ap)\n",
    "            value_list.append(percentage)\n",
    "        elif percentage < 5.0 and percentage >= 1.0:\n",
    "            between_1_5 += percentage\n",
    "        else:\n",
    "            less_1 += percentage\n",
    "    ap_list.append('< 1%')\n",
    "    value_list.append(less_1)\n",
    "    ap_list.append('1% to 5%')\n",
    "    value_list.append(between_1_5)\n",
    "    \n",
    "    if draw_graph:\n",
    "\n",
    "        fig_size = plt.rcParams[\"figure.figsize\"]\n",
    "\n",
    "        fig_size[0] = 5\n",
    "        fig_size[1] = 5\n",
    "    \n",
    "        labels = ap_list\n",
    "        sizes = value_list\n",
    "\n",
    "        fig1, ax1 = plt.subplots()\n",
    "        ax1.pie(sizes, labels=labels, autopct='%1.1f%%', shadow=True, startangle=90)\n",
    "        ax1.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\n",
    "\n",
    "        plt.show()\n",
    "    \n",
    "draw_ap_freq(ap_freq_dict,total_time_each_usr, 787, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# c=0\n",
    "# for usr in user_dict:\n",
    "#     for it in user_dict[usr]:\n",
    "#         if it[2] <= datetime.timedelta(minutes=1):\n",
    "#             c+=1\n",
    "#             print(it)\n",
    "            \n",
    "# print(c)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ss = 1114922\n",
    "# final_data_list[ss-10:ss+10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# small = datetime.timedelta(seconds = 50)\n",
    "# test = final_data_list[ss-10:ss+10]\n",
    "# test1 = []\n",
    "# for i in range(len(final_data_list[ss-10:ss+10])):\n",
    "#     if i % 2 == 0:\n",
    "#         test1.append([test[i][0], test[i][1],test[i][2],test[i][3],test[i][4]])\n",
    "#     else:\n",
    "#         test1.append([test1[-1][0], 7,test1[-1][2] + test1[-1][4],test1[-1][3],small])\n",
    "\n",
    "# for i in range(len(test1)):\n",
    "#     if i % 2 == 0 and i !=0:\n",
    "#         test1[i][1] = test1[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dt = datetime.datetime(year=2018,month=2,day=23,hour=16,minute=22,second=44)\n",
    "# seconds = dt.timestamp()\n",
    "# print(start_ts,end_ts)\n",
    "\n",
    "\n",
    "# start_ts1 = datetime.datetime(year=2018, month=2, day=23)\n",
    "# end_ts1 = datetime.datetime(year=2018, month=7, day=16, hour=23, minute=59, second=59)\n",
    "# print(start_ts1,end_ts1)\n",
    "# start_ts1 = int(start_ts1.timestamp())\n",
    "# end_ts1 = int(end_ts1.timestamp())\n",
    "# print(start_ts1,end_ts1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def convert_datetime_to_timestamp(input_time):\n",
    "#     return int(input_time.timestamp())\n",
    "# def convert_timedelta_to_seconds(input_time):\n",
    "#     return int(input_time.total_seconds())\n",
    "# def convert_timestamp_to_index(input_ts, start_ts, window_in_minutes):\n",
    "#     index = math.floor((input_ts - start_ts) / (window_in_minutes * 60))\n",
    "#     return index\n",
    "# # create a time slot 2d array each row is a user and each cols is a timeslot.\n",
    "# # for a particular user if there is no information on a particular time slot append(-1)\n",
    "# # this function is not finished\n",
    "# # Input:\n",
    "# # - df: dataframe\n",
    "# # - userdict: list of user id\n",
    "# # - start_timestamp: start time timestamp\n",
    "# # - end_timestamp: end time timestamp\n",
    "# # - window_in_minute: time window, use 60 (1 hour) first for simplicity\n",
    "# # \n",
    "# # Output:\n",
    "# # - result: a hashmap (dictionary) where each map item is a 1D array where array \n",
    "# #           indexes are indexed timeslot and values are \"Map Location\" (integer value)\n",
    "# #           -1 if there's no information for that timeslot\n",
    "# def create_time_slot_data(df, user_dict, start_timestamp, end_timestamp, window_in_minutes,usr):\n",
    "#     # calculate number of index in each array\n",
    "#     # Formula:\n",
    "#     # number_of_time_entry = (diff of timestamp in second) / (number of seconds in that time window)\n",
    "#     number_of_time_entry = int((end_timestamp - start_timestamp) / (window_in_minutes * 60))\n",
    "    \n",
    "#     # Addumption: start date at 0:0:0, end date at 23:59:59\n",
    "#     # 86400 = seconds in a day\n",
    "#     number_of_days = int((end_timestamp - start_timestamp) / 86400)\n",
    "    \n",
    "#     number_of_time_entry_per_day = int(86400 / (window_in_minutes * 60))\n",
    "#     #print(number_of_time_entry_per_day)\n",
    "#     result = {}\n",
    "#     #for i in range(df.shape[0]):\n",
    "# #     for usr in user_dict:\n",
    "#     if usr % 10000 == 0: print(usr)\n",
    "#     client_username = usr\n",
    "#     for i in range(0, len(user_dict[usr])):\n",
    "#     #print(user_dict[usr][i][0])\n",
    "#     #print(convert_datetime_to_timestamp(user_dict[usr][i][0]))\n",
    "#     #print(user_dict[usr][i][1])\n",
    "#     #print(convert_timedelta_to_seconds(user_dict[usr][i][2]))\n",
    "#     #client_username = df.iloc[i,0]\n",
    "#         association_time = convert_datetime_to_timestamp(user_dict[usr][i][0])\n",
    "#         map_location = user_dict[usr][i][1]\n",
    "#         session_duration = convert_timedelta_to_seconds(user_dict[usr][i][2])\n",
    "\n",
    "#         # 1/ If there's no entry for this user in result dict\n",
    "#         #    create a new 1d array with all -1 \n",
    "#         #    then change values base on association time and session duration\n",
    "#         # 2/ If user already in the result dict\n",
    "#         #    then change values base on association time and session duration\n",
    "#         # Caveats: there's maybe duplication, ignore it for now\n",
    "#         if client_username not in result:\n",
    "#             #time_entry_ts = start_timestamp\n",
    "#             #while time_entry_ts < end_timestamp:\n",
    "#             result[client_username] = [-1] * number_of_time_entry\n",
    "#                 #time_entry_ts += 86400\n",
    "#         # convert association time to timestamp\n",
    "#         # and calculate the total sesstion in timestamp\n",
    "#         association_time_ts = association_time\n",
    "#         end_association_time_ts = association_time_ts + session_duration\n",
    "#         if (association_time_ts > end_timestamp): \n",
    "#             continue\n",
    "#         # TODO:\n",
    "#         # Need to handle the case where association timestamp < start_timestamp\n",
    "#         # in that case, some array entry might change\n",
    "#         start_index = convert_timestamp_to_index(association_time_ts, start_timestamp, window_in_minutes)\n",
    "#         end_index = convert_timestamp_to_index(end_association_time_ts, start_timestamp, window_in_minutes)\n",
    "#         # mark all the index from start index to end index to map location\n",
    "#         for i in range(start_index, end_index):\n",
    "#             result[client_username][i] = map_location\n",
    "       \n",
    "#     #print(result)\n",
    "#     # Now we have a result dictionary without date\n",
    "#     # Do some more calculation to convert this to a dict with\n",
    "#     # {userid, date, list of timeslot}\n",
    "#     output = {}\n",
    "# #     day_track=[1]\n",
    "#     for user in result:\n",
    "#         output[user] = {}\n",
    "#         date_ts = start_timestamp\n",
    "#         output[user][date_ts] = [-1] * number_of_time_entry_per_day\n",
    "# #         summ=0\n",
    "        \n",
    "#         for i in range(0, number_of_time_entry):\n",
    "#             if (i != 0) and (i % number_of_time_entry_per_day == 0):\n",
    "#                 date_ts += 86400\n",
    "#                 output[user][date_ts] = [-1] * number_of_time_entry_per_day\n",
    "                \n",
    "# #                 if summ <= -288:\n",
    "# #                     day_track.append(0)\n",
    "# #                 else: day_track.append(1)\n",
    "# #                 summ=0\n",
    "\n",
    "\n",
    "#             output[user][date_ts][i % number_of_time_entry_per_day] = result[user][i]\n",
    "# #             if result[user][i]==-1: summ-=1\n",
    "        \n",
    "\n",
    "#     return output\n",
    "\n",
    "# output = create_time_slot_data(df, user_dict, start_ts1, end_ts1, 5,4900)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n",
      "20000\n",
      "30000\n",
      "40000\n",
      "50000\n",
      "60000\n",
      "70000\n",
      "80000\n",
      "90000\n",
      "100000\n",
      "110000\n"
     ]
    }
   ],
   "source": [
    "# datetime.datetime.fromtimestamp(1519376400).strftime(\"%A, %B %d, %Y %I:%M:%S\")\n",
    "def segment_count(user_dict):\n",
    "    c=0\n",
    "    usr_segment = defaultdict(lambda: defaultdict(int))\n",
    "    total_usr_segment = defaultdict(int)\n",
    "    total_segment = defaultdict(int)\n",
    "    for usr in user_dict:\n",
    "        c+=1\n",
    "        if c%10000 == 0: print(c)\n",
    "        for i in range(len(user_dict[usr])-1):\n",
    "            user_loc1 = user_dict[usr][i][1]\n",
    "            user_loc2 = user_dict[usr][i+1][1]\n",
    "            segment = [user_loc1, user_loc2]\n",
    "#             segment.sort()\n",
    "            segment_key = ' > '.join(str(x) for x in segment)\n",
    "            usr_segment[usr][segment_key] += 1\n",
    "            total_usr_segment[usr] += 1\n",
    "            total_segment[segment_key] += 1\n",
    "    return usr_segment, total_segment, total_usr_segment\n",
    "\n",
    "usr_segment, total_segment, total_usr_segment = segment_count(user_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5920"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = [i for i in total_segment.values() if i > 100]\n",
    "len(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAEmCAYAAAB7zsvVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvIxREBQAAIABJREFUeJzs3Xd8VGXWB/DfuXf6ZPokISEhoUpH\nkC6oiIJisKwlduxlq6+xu7qs7bXF3Xct67quZV1LdO2xoDRBQxMEYgCpSSC992Rm7n3eP2aAAOmZ\nyZ2Z+3w/n3xIZm45E+DMnec+zznEGAPHcRwXeQSlA+A4juP6hidwjuO4CMUTOMdxXITiCZzjOC5C\n8QTOcRwXoXgC5ziOi1A8gUc4IkomolVEtJOI8ojoD+2ee4aIdhHRdiL6mIjs7Z6bSETrAvvkEpGh\nn3GMDhyvjYjuOu6514ionIh+Pu7xSwPnl4loan/Oz3FqxBN45PMByGCMjQEwE8BviGhs4LlvAYxn\njE0EsBvA/QBARBoA/wFwG2NsHIAzAHiPPzAROXoRRzWA3wN4toPn3gBwTgeP/wzgVwDW9OI8HMcF\n8AQe4RhjJYyxLYHvGwDsBDA48PM3jDFfYNP1AJIC3y8AsJ0xti2wXRVjTOrg8M8Hru6v6u4KnTFW\nzhjbhA7eCBhja+BP8Mc/vpMx9kuPXijHcSfgCTyKEFEqgMkANnTw9A0Avgp8PwoAI6JlRLSFiO7p\n6HiMsasB3AVgNoA8InqeiCYFPXCO4/qEJ/AoQUQxAD4EcAdjrP645x6Ef6jl7cBDGgBzAFwV+PMi\nIprf0XEZY5sZY78BMA7AXgAbiejO0LwKjuN6Q6N0AFz/EZEW/uT9NmPso+OeWwIgDcB8drTwzSEA\n3zHGKgPbfAlgCoAVHRxbA2ARgOsBjATwMPzj5xzHKYxfgUc4IiIA/wKwkzH23HHPnQPgXgDnM8aa\n2z21DMBEIjIFEvTpAHZ0cOw74b/5eTGAvzDGxjPGnmKMlYfo5XAc1wvEqxFGNiKaA2AtgFwAcuDh\nBxhjXxLRXgB6AFWBx9czxm4L7Hc1/LNSGIAvGWMnjIMT0VkANh4/JNNJHIMA/AjAGoijEcBYxlg9\nEb0L/0wXN4AyAH9ijP2LiC4C8DyAWAC1ALYyxhb24dfAcarEEzjHcVyE4kMoHMdxEYoncI7juAjF\nEzjHcVyE4gmc4zguQvEEznEcF6F4Au9EbyvoEZErUDekkYheCFIMVwUqCW4nopzDy9i7qkAYeP53\nRPRL4LmngxELx3Hhh6/E7NwbAF4A8O/jHj9cQe8fxz3eCuAhAOMDXx0iIgdjrKaHMRwAcDpjrIaI\nzgXwCoAZOFqBcAsRWQBsJqJvGWM7iGgegAsATGSMtRFRXA/PFbFS7/tCBOAA4ARgAiAe/lpY/q00\nqmmvAECC//cmAWiBf258TUZWNp9Hy0UsnsA7wRhbEygOdfzjOwHAvwDymMebAHxPRCO6OfTzRDQY\nwKsAPmSMtXYRQ067H49UE2SMlQAoCXzfQESHKxDuAHA7gCcZY22B5yN21WTqfV+4AAwLfA0FkAjA\nFfhytvvTBoA6OobDW/MDgFM7OYWUmZ5WDaCyg68KAAXwV3fcm5GVfUKVRY5TGk/gA4wxdjURnQJ/\ndcBHAnVIXj1c2rULN+JoNcEjOqhAOArAXCJ6HP5PBXcFyryGrdT7vkiGvxbLmMDXaAAnwZ+Y+0WW\nJF0XT4vwrwKN7eYwvsz0tP0AdsGf0Hcd/j4jK7uuvzFyXF/xBK4Axthm+Ic9DABuhb/C3/3H1zI5\nLDAsciP8lQPbP95RBUIN/MMJMwFMA/A+EQ1jYbLkNvW+L4wApsIf30z4h4QGh+p8za0tQ6Dt92E0\n8L8xjgJwfvsnMtPTDgH4Af5yBmsB/JyRlS2fcASOCwGewBXQmwp/RDQR/uGWcxljVe0e76wC4SEA\nHwUS9kYikuGvQVIRitfSndT7vogDcDb8NcVnApiIAfx3JwiCJ8SnSAKQHvgCgNrM9LQcHE3omzKy\nskMdA6dSPIEPsECFv9/C/5/7L4FuNZ1tOwTARwCuYYztbvd4pxUIAXwC4EwAq4loFAAd/GO6A2Op\nTTy19f+mFyE2Df42apPRyfh0lLLD/+a8KPBza2Z62kYA2QA+ysjK3qdYZFzU4cWsOtGXCnpElA9/\nNT5d4LkFjLEdxx23NxX+XoW/lGtB4CEfY2xqNxUIdQBeA3AyAA/8Y+Ar+/Zb6KGlNiP8bdouBJD2\nonfxrmekK+Z0s9eAOH/vGwdTxJZkpeNoZzv8b8ofZmRl/9zdxhzXFZ7Aub5ZajPA/+ZyCfzJ23T4\nqXX1ceVX6P4aFtMXwzCBt7cbwMfwX5lvVDoYLvLwBM71zlLbaAC3MsauJSJnR5t4ZPKOb32VPIJR\n8SG6ME/g7R2Ef83BKxlZ2YVKB8NFBp7Aue4ttekBXMwYu5WITuvJLjfV3lC83HBWYogj61YEJfDD\nZABfAvg7gK/5jBauK4pfIXFhbKltFIBbGGPXBUoF9HjXxfS9dznOCl1s0UuAv4dpGoADmelprwD4\nV0ZWtiKziLjwxq/AuWMttekAXAT//PR5fT1MtUdTP0X+tzVocfVRBF6Bd8QD/5TRv2dkZa9VOhgu\nfPAEzvn5Z5Lcyhi7h4gSgnHIhfUPVf+iG9PhOPlAiZIE3t4PAP6ckZX9rdKBcMrj1QjVbqnNiKW2\n/5EZywfwl2AlbwBYLK9sCNaxuCNOBfBNZnra2sz0tPlKB8MpiydwtVpqM7A/We+QZFYA4DkhBFUL\nz9blGoJ9TO6IOQCWZ6anrclMTztT6WA4ZfAhFLVZahNkxpYwhsdEgUI6S0RmYJObXmyt0ziMoTxP\nV6JwCKUzawD8KSMre7XSgXADh1+Bq8lS22KvxHYIRK+FOnkDgECghb6VA7eMX91OA7AqMz1teWZ6\n2hilg+EGBk/garDUdrLnIet6AJ9pRTppIE+9SNzQ/UZcMM0HsC0zPe2pzPQ0s9LBcKHFE3g0W2oz\nND9o/YvM2I86kWYoEcJ0Y3EsMYmP0w0sLYB7AOzKTE+7ROlguNDhCTxK1dxrnd/sZXtNWrpDIBKV\nisOkkQ0zPBsjtitQhEsC8EFmetqyzPS0kUoHwwUfT+DRZqnNUn2v9R27ActNWgpZo4TeWMy+a1E6\nBpVbACA3Mz3tscz0NMVuKHPBxxN4FKm+13pRi5flO410RW+WvYfaPMNuxVdkctADeBBAXmZ62ulK\nB8MFR9gmcCJ6jYjKiejn4x5fSkRFRLQ18LWo3XMTiWgdEeURUW6gZVl/YhgdOF4bEd3Vw/icRPQt\nEe0J/OnoTww90fpHq7vmXusXTiN9ZNR2XCFQSYmGVudgb2G39c+5ATEUwMrM9LSnM9PTuuoXykWA\nsE3gAN6Av6NLR/7CGDs58PUlcKRN2X8A3MYYGwd/M4YTOon3MqFWA/g9gGd7Ed99AFYwxkYCWBH4\nOWSq7rHcRMABh/HoG1k4SvOtqFE6Bu4IAcDdADZlpqeNVzoYru/CNoEHWo1V92KXBQC2H+7uzhir\nYoxJHWz3PBGtIqKrurtCZ4yVBzq6n/BG0EV8FwB4M/D9m/B3qQm6uvus5qp7LF+7TMI/9RqKCcU5\ngukc7Zb+txbmgm0igB8z09N+o3QgXN+EbQLvxm+JaHtgGOPwFfUoAIyIlhHRFiK6p6MdGWNXA7gL\n/ia7eUT0PBFNCmJs8YyxksC5SgAEfYn6j7fEzAKwz2USFgb72KEy3lQVp5ebT3gj5BSnB/BCZnra\nh5npaXalg+F6JxIT+N8BDIe/52MJgMzA4xr460NcFfjzIiLqsNgPY2wzY+w3AMYB2At/9/Y7Qx14\nf51/kpa23BrzwMR4YY3NQPFKx9MbWgGaMz1r+HTC8PUrAFsz09NmKh0I13MRl8AZY2WMMYkxJgP4\nJ4DpgacOAfiOMVbJGGuGv6vJlI6OQUQaIjofwLsAbgbwMPzj58FQdriiX+DPoCSt05bEm646N+bD\nKQni4zqRIrIRR5rwQ0dDWlz4SAHwXWZ62vVKB8L1TMQl8OPKnV4E4PAskGUAJhKRKXBD83QAOzrY\n/074m8leDP/N0PGMsacYY8G6OvwMwJLA90sAfNrfA865JWFUw2R73pOjB51zSKbm/h5PKacaC8Ju\nhgx3Ah2A1wJL8cNnLirXobBN4ET0LoB1AE4iokNEdGPgqacDUwS3w98x5n8AgDFWA+A5AJsAbAWw\nhTH2RQeH3g7gZMbYksCNyK5iGEREhwDcCeCPgTis3cT3JICziWgPgLMDP/fZpJsTr2mYbP/R59Cl\n+owa45XuuHqP/9NHxLFrfTHjPdt5cavIcA+Aj3g9lfDGy8mGKetkK7kWuv5sHml6gDTCMUvhTylp\nKHijtSZFqdj64+XaGflPGv6QOlDnU1E52VD5CcDijKzsIqUD4U4UtlfgamadbNXHnh/7gXm0+aHj\nkzcAbE6wpLxExoNKxNZfZ+vy+BVdZJkMYGNmetpUpQPhTsQTeJixTbc54y6MW2EaZrq4q+XwLye7\nB+XImqoBDC0ohhob3U6pMmLH8VUqEcCazPS0i5UOhDsWT+BhxD7bPjT2/Ni1xlTjqd1ty0TS/i4x\nTlMuU+tAxBYsAoHO8a7g4+CRxwh/ZUO+6CeM8AQeJpxnOsfFLY5bYUw2ju3pPh6jxnaFM7baF2E3\nMhaJG/m/u8hE8C/6+YPSgXB+/D9SGHCd5Zoae27sMn2ifmhv9y13GBJ/p3cUhCKuUDnFVBorMk9E\nzqThAAB/zUxPC/uFb2rAE7jCXPNdc93nuD/Txen6XLv7+0RL6uswHgpmXKFkFJl+VtsGviozsmVm\npqfdrXQQascTuIKcZzgXuhe539fF6hK637oLRPhLsivuJ1kTMRX/FtOaNqVj4Prt6cz0tPuVDkLN\neAJXiHOec1Hs4tg3dW7doGAcj2kE3S0JcaiR4QnG8ULtDMMem9IxcEHxRGZ62kNKB6FWPIErwHGa\n49zYtNjXdG5dUAtStZo0jivsseVyBNzTjNd77Cne/bVKx8EFxSOZ6Wl/VjoINeIJfABZJ1vJNs22\nMHZR7D+CnbwPK3IZk+7S2vJDcexgW+xbUad0DFzQPMxnpww8nsAH1lnuc91/0yfoQ7q0+9skW8r7\nTF8cynMEw0LdVt7SK7o8l5meFpIGJlzHuk3gXfR+nBToF5lLRJ+3K/LkCnS8aSSiF47bJz3QiCGP\niJ4OxgvoQ3ypRNTSrqfmy+320RHRK0S0m4h2EVHQVp5ZJ1tnOc90Pm0abhoVrGN2iogeT4517pTF\nsO5DOcZYE2eSGiJizJ7rEQHA25npadO73ZILip5cgb+Bjns/vgrgPsbYBAAfw99jDwBaATwEf9eb\nI4jIBeAZAPMDPSvjO2q4QEQ2IurNJ4PexgcA+9r11Lyt3eMPAihnjI0CMBbAd72Io1PWydaxtum2\npywTLScH43g9IWsFw3Xxcd4GdmI7uHChESCe5V3NpxNGFxOAzzPT03q9poHrvW4TZRe9H08CcLgc\n67fw19cGY6yJMfY9/Im8vWEAdjPGKgI/Lz+8z3HmAPgl0H1+SLDj68YNAP43cFyZMdbvJd/WydaU\nhT7jk4/lGoaKHnlAGxo0x2hdV1ncpQN5zt5KE9bxBT3RJw7Al5npab1pIM71QX/GwH8GcH7g+0sB\ndDeuuxfA6MAQhgb+Zr8n7BOo4T0LQC2ATwM9Li8lot6Ol3YV31Ai+omIviOiuQBARIf7AT4a6Kn5\nAVH/2pZZJ1tjx8naR+7z2s+eXq1JevIFb6W5ThrQQk4HYk3JD4mWsF2pOct40B2h5c25ro0G8Elm\nehq/zxFC/UngNwD4DRFtBmABup5/HGi4cDuALABrAeQD8HWybSVj7K+MsckAlgJ4BMCPQYqvBMCQ\nwLHvBPBOYHxcAyAJwA+MsSnwN2t4tpfnPGKexWI+uZReeKLVebEJggEAUtrE+OdelryDDvkGdMHN\nJ0n25M+ZLiyvxC1ayTTZu7Wi+y25CHQagNd5Z5/Q6XMCZ4ztYowtYIydAn9vyX092OdzxtgMxtgs\nAL8A2NPZtkQ0loieAfAWgBz4e1f2Oz7GWBtjrCrw/ebA46MAVAFohn+8HAA+QCc9Nbszz2LRiMAt\n9xvdcwaR5pj61w5ZsD31FjOOzfUOXEIVSHgoKc66TxYaBuycvbBYXt10+HsmSyh+/fco/2/H04qb\ndq5F8au3o/jVX6Pis2cAAN6qQyh54w8ofu23aCvaeeQ4Ze89CK/Px5OHsq4EwFdrhkifEzgRxQX+\nFAD8EcDLXe9xzD4OAL+G/0bj8dtMIaL1ged2wd/+7EbG2IZgxEdEsUQkBr4fBmAkgP3MX9HvcwBn\nBA4xHx301OzOPIuFAFyyxOG8MVWnS+xoGyPI8FA2Yuet9AxYUwZJJ5iuiYtrbZFZ2DUWnq/fEXP4\n+4YfP4PW1fFonLe6CHXrP0D81c8g8aaX4Jzvf09v2PoV7Kdfh9gL70f9Rv/7b8NPX8I87kxoNZrw\nX9UU/R7JTE+bo3QQ0agn0wg76/14BRHthj/JFgN4vd0++fD3p7wusM/hEqn/R0Q7APwA4EnG2O4O\nTtkC4HrG2GzG2L8YY41Bju80ANuJaBuA/wK4jTF2+CbovQCWBvptXgMgo7vfTwfmnmoy3zLVZBrX\n1UYiSLx9g5B8zftt+X04R580WHSxS2LcYdcaK8XQ7I71lTb56ivRsn8TYiYt6HC7xm3LYJlyHkSD\nP9+LZv9tCxI1YD4PmK8NEETIrY1o2bsR5vFnDthr4LokAng3Mz3NpXQg0Yb3xAyieRbLqDiN5tH7\nY+MW6wXB2NP9Njt9B5+9QZcoaU9snxYKVxVUFd4nN3U7w2cg/anmvMJnvy4YYp11GZinGfUbP0bc\nJX86Zpvyjx6D1pGItqKdYLIM+5wrYRx2Cnz15ajMfg5M8sK18LdozF0O08iZMAyZwHtihpfsjKzs\nxUoHEU34SswgmWex2ATgt7c6XbN6k7wB4JRqTfL/vuCtNNdLLaGKr723k52DVzBtWN04NB5YbRbM\ndugHjeh8I1mCt6YY8Vf8L9zn342qr/4GubURGmscBl35JBKuyQRp9ZAaq6F1JaEyOxNf5OS4Khq6\n/BDHDZy0zPS0/1E6iGjCE3gQzLNYBADXX263z0rQavt0tZfaKsZnviy1xRf5Ql/gSSDxrsFxxkMy\nhU1vysrKKnvLnvU49PcbUPHZ02gt2I7Kz4+dBCRaXDCNnAkSNdDaB0HrGgxvzbEVA2rXvAX73KtR\nv/lzmMeegZnjxtV9k9fpvXJu4D2VmZ42TekgogVP4MExf4LBsGC2ydynWSuHOSXB/vRbTD/6Z29Z\nsALrjE8vxlzpjmvwhMkk7GcXGMRrbryuOOn21xB7/j0wpEyEe/Exi3lhGjkLrYXbAQBScx281cXQ\n2I9W420tzIUY44TWORjM2wYQgYjglcLuvq2aaQG8l5mexssJBwFP4P00z2JJNRBdc7XdMUPoXQmA\nDhkZGR/+HO7TV4d+hkqNTR9/s9HZ4/PUtjJc8n4zRr/QiDEvNmLdwWOn8e+qlDDrX03QP1aPZ3OO\n9muoaJIx57UmjH+pEZ/sOrqy/4L3mlHccPT9YzF9f8Ky/9q1/0HzHv8EJMPQKRAMFhS/ejvK3n0A\njjOuh2i0AgAYY6jLyYLt1CsAAJZJ56D2uzfx5fp17tNPGtbTl8gNjGEA/ql0ENGA38Tsh3kWixHA\n0tucroUTjcZJwT7+JyN8Be9cakgJ9nGPd0t+5cHfseZuh36WfNKCuUNE3DRFB4/E0OwF7Iaj06zL\nm2QU1DJ8sssLh5Fw12w9AOBvG9pg1BAuH6/FOW8344cbzPj8Fy+2lMj40xn6I/tXerR1U+U3g3pl\nxm9ihrXLM7Kys5QOIpLxK/D+uXia0ThhgsEQ9OQNABfu1aTc9UproegNbQ2VV5JdCT/Imi7rvtS3\nMawp8OHGyVoAgE6kY5I3AMSZBUwbLEJ73FwarUBo8TG0SQwCAT6Z4a8bPLj71GNXWbt1XtsIz+6I\naQvH9dtfM9PT7N1vxnWGJ/A+mmexjDMLwrmX2R2ziUK32G96lWbI4y96K4wN0vHFwYJHJM3vEuN0\n5TJ1Ogtmf42MWBPh+k9bMfkfjbjpsxY0eXr26e3KCVos2yfhnP80Y+npery0yYNrJ2ph0p74e1ss\n8yYPKjIIwJNKBxHJeALvg3kWSwyAm69zOMeZBSHkN2OGtYiDnvu71BJb4gtZcvMaNdbLnbE1vk7G\n1HwysKVExu1Ttfjp1hiYtYQnv+9ZX2KbgfDFlSb8eEsMpiSIyN7tw8Vjtbj5sxZc8n7zMWPpC7Tb\nDcF5RVyEuCUzPe1UpYOIVDyB91JgqfzlY/X61LF6/cSBOq9LEhzPvCnrRu0I3QyVCoch8Td6R4eV\nC5OshCQrYUaSBgBwyVgNtpT2fgLLI9+14cG5eryb68UpiSJeu8CIB1YefSMYZaqLs0i1ofu0wYUb\nAvCPzPQ0rdKBRCKewHtvIoDTLrc7TqFQjp10wMQE49JP4Zq7JnQzVHIGW1P/BeOh4x8fFCMg2Sbg\nl0r/cPyKAz6Mdffun8+eKgnFjTJOT9Wg2esfDycAre0ms4gE4WzPqrBaZMSF3Dgc23CF6yE+C6UX\n5lksBgBPLLZYx5xrtXbUBWhAMDB8PErOf+9ifWoojk8+2fNGYWnTFPIdU5B/a6mEmz5rgUcChjkE\nvH6BEVl5/pl/t03VobRRxtRXmlDf5k/OMTrCjt/EwKr3v89d9kEzHj9Tj5EuEeVNMi58rwV1bQyP\nnKHHxWOPXoCtrE8+eIPuqaDMHOGzUCJGK4AJGVnZe5UOJJLwBN4L8yyWxTGCkP5I/KALDYJg7n6P\n0Frvlgr/ep02SdYKQf8kpW/21XxTWmxyEvTdbx1cjT6hZbz3TQNI7PcnHJ7AI8ryjKzss5UOIpLw\nIZQemmexxAG4YMboRYlMY9IoHQ8AzKwUhzz+orfc2Bj8GSptJo3jCltspazAG3yMRjZO82zmwyjq\nc1ZmetpFSgcRSXgC74HAjct0u3O4yTbphtO+n/WY9GPCGYUSg+IfX4a3iIMyX5Ja3KW+oHegL3YZ\nB2fobIq0Y1vMVg9IYS8u7DyamZ7G81IP8V9UD7QYXLM8GtM5U6bdPlEQRFHUGk31J106ZPmMP1fv\nsY0uUTo+tyQ4nnlD1ozc6Qt6h/flg21DsmAo7n7L4Jpn+CWm+624KDQOwFVKBxEpeALvxoTU2Zpm\nY/wl1uQ5w53ukcc0adCa3K6Dk3+X8M3EO4rK9e7QVxHsgpkJpj9/wpynfu85YQZJvxDRE0luZ54s\nDugCm2RDiyvBWxSWLeC4kPszn1bYMzyBd28GE0Tn3EmXd1rjW+McOTh3xsPW1SOuLGgWDYrNYdaA\nNL9fS0mXfdR2zLCH7JGx78/7sPehvdjzwB6UfXziVHLZK6PwpULsvmc39j2yD54Kfw/opj1N+OXP\n+wzTX282b62UvIC/qNXC/zQh1DfAz/Mtr+5+Ky4KDUUve+CqFU/gXZiQOtsIIH1s8nSTzezqsoMN\nCaIgJ52a8sPMx9mmxDMLlBofJxAu+UVMueNfrYXkk2UAIC0h9d5UjHh0BEY8MgKNuY1o3ntsKfCa\nNTUQTSJGPT0KrgUulH7g77lc9XUVhvx2COIuT9Bc9JPYCgCPfteGB+boEepp8OdqN/OrMPX6Y2Z6\nWq8ao6gRT+Bdmw/AMjF19tSe7iBqDcaGURenLJ/xSM1u+5gBHzs+bHa5ZsjjL3rLjI1yGxFBNPgr\nTDGJgUnMv4KmnYafGuCY45/2bZtmQ9OOwBW2CDAvg+yR0WjXWW6vMRQVNfgX44TaBFNlnF5u8XW/\nJReFEgD8Tukgwh1P4J2YkDrbBuD8ofFjmd3sHtrb/bUml/PQyb9N/GbSncXl+lhFxsdHNIsJz/7d\n2+Qq89UzmWHvQ3ux6/e7EDMuBqbhpmO29dZ4oXX6L3hJJAhGAVKjhNjzYlH0ehGqvqmC6ywX3l3X\nmnja6TEDMsVPJ0Bzumdt0G/MchHj3sz0NKvSQYQznsA7NxeAZvKw06b35yAax/DE3BkPWVePvKqg\nSYHx8Vif6Hz2dVkzYo9UMeLRETjpuZPQsr8FrYeOC6WjAR8CjClGDH94OIbeNxSeCg80Ti393yBX\nzLlZLb6rP2pBWWNoG/qk0Q8nNHngVMMJ4E6lgwhnPIF3IDD2vSjentwWa00c29/jkSAK8uDZKTmz\nHmcbE+cX+EAD2sbMzATTIx8xx6wczyHRLMI82ozG3GMb/WqdWnir/bmSSQxyiwzRfLSwN2MM5Z+V\nI+78OJR9WWks+VVi/aXjNfLfNnhCGvsc4wFnSE/AhbvfZKan8QqVneAJvGPTARinjTjrFCIhaHfq\nRI3B2DjqVykrZjxSt9s+dsDGx6t9PrRIsuYP39Hgxf9tKWjc0QhdwrHNFCwnW1Dzvb+XQt2mOpjH\nmI+5SVn7fS0skywQzSJkj4xmq875tM5a2Rzi62OnzmcZ48njs1HUyw3gcqWDCFc8gR9nQupsDYAL\nrEZHU4IzdXIozqE1Oh2HTv5N4jeT7iwuM8SFvANNhc+H6w4W4lcH8umDbw6mnN6ir7WNj5HLPipD\n/U/+BZyO0xyQGiXsvmc3qpZVYdClR5sFy20yan+ohetMFwDAvdCNwhcKsWV1XZw81VYU6vjT5JVB\nX2XKRRR+M7MTvJjVcSakzj4FwG/PPvnyocMHjT891OdjTJbF4g0Hp+37MM4stwzYtKndZqn4sRu1\nrlaz0L9iVTKTnjtQWnW24I0LUmgn2NNsKT9b+Eefjs+LWUWNuRlZ2d8rHUS44Vfg7UxInS0AuFCv\nMTQNiR3Vr5uXPUUkCPLgWSk5sx+njYPPHrDx8VFNYuKzL3kbnRVS/1Y7CiTekxRnOiRTc/cb981w\nY0Os3VfFa6Oo2++VDiAc8QR+rJMAJE8ftWCYVtQN6CICUaM3NI68MGXFjEfrdjkm9Hh8vE2WkV6Q\nj4vyD2Dxgf14vvLEGX4eWcadxUVYuH8f0gvyUeT133g8VN/mOvTgPnPhvXt8bWX+rjhSk4T8Z/N7\ntcrSpxdjrnDHNbTKLCRvPgL64VZqAAAgAElEQVSBzvGu7LLpMhf1LspMT0vqzwGI6DUiKiein497\n/Cki2k5E/2732DVE9IdOjpNKRFf28twpRLSZiLYSUR4R3RZ4XE9EXxPRz0T063bbv0JE3Q7h8gQe\nMCF1NgFYDKApNW70KUrFoTU6HMWTbkv85uS7iksN8d3evNMR4bXkIfg4dSg+Sh2K75uasK3l2IvV\nD+vqYBVELBs2HEscTmRW+JP8GzXVeGFwkvCUNhaaf5c3AkD5Z+WITYvt9SrLWps+/maTK2SdghZp\nNobq0Fxk0AC4vZ/HeAPAMY1YiMgGYDZjbCIAkYgmEJERwHUAXurkOKkAepXAAZQEznMygBkA7iOi\nRAALAWyGv9PXLYGYJgEQGGM/dXdQnsCPGgJgbErsSYLZYA3ZeG5PaexDE/Nm/NG+atS1BY2isdPh\nAyKCOdDPwccYfB1cOa9sbMSFNn/v5QUWC9Y3N4MxBg0R2mQZPplpZpWIMXPfaSjy1fhgHt23XhVb\nE2JS/kamwj7t3I2pxpJYgXkHdPolF3Zu6c+UQsbYGgDHXxTJAHSB9ohGAF7427v9jTHW2RyrJwHM\nDVxN/w8RGYjodSLKJaKfiGheB+f2MMYON3/V42ju9QbO235p86MAHu7Ja+IJ/Kh5ADxjk6cNWKPi\n7hAJAkuckbJu1uPChqQF+Z2Nj0uM4aL8A5izdw9mm82YZDx29KfM58Ugjf/fh4YIFkFArSThZqcL\nfyorxVs1Nbja7kD+uurBd8i2IpLkPt/Z/meyK/F7WRP04Q6TRjbM8GzkqzLVzQ3gsmAekDHWAOBD\nAD8BOACgDsA0xtinXex2H4C1jLGTGWN/AfCbwLEmALgCwJtEdMIbDRElE9F2AAcBPMUYKwbwLYBB\nADYAeJqIzgewOfBct3gCBzAhdbYBwGwiKh/kSJ2gdDzHEzV6fdOIC1L94+MTT/iLFYnwcepQrBo+\nArktrdjT1nbM8x0usiTCGIMB76Wk4o0hQ3DI60WcRoMZVZrBpjsLWotfKJR9dX0oQyKS5veD43Wl\nMgX9puNirOHd6rlrgn1AxtjTgWScgcDVLxHdRETvE9Efe3CIOQDeChxrF4ACAKM6OM/BwFDNCABL\niCieMeZjjF3JGJsM4AMAdwDIJKLniOi/gYTeKZ7A/cYC0IxNmpas1xosSgfTGf/4+K2J35x8V0mJ\ncdAJ4+NWUcQ0kwlrm45dZTlIo0Wpz5+MfYyhQZZha9dGkzGGl6sqcZvLjRcrK/GQI86YUW5ubPy4\nok/LLL0G0XqFM67WF+Q5qvMMu23BPB4Xkc7MTE8b1P1mvdfupuFuANcyxi4DMJ6IRna3a2/OE7i6\nzoO/XEd7vwbwJoBZADwA0gF0+QbCE7jfaQCaRyZOmqR0ID2hsQ9N2DH9QcfKUUsKCpm2uV6SAACt\nsox1zU0Ypjt2ave8mBh8Uufvx/BNQwNmmEzH3KT8pL4Op8fEwCaKaGUyBCLEyRrr7G0Spe719Wk4\npNKhT/i13hHUdmwJ+jZHkreAL+pRNwGhW5l5eOxZC+BwHQkZgOm47RoAtL/QW4NAFyEiGgX//bRf\n2u9AREmBm6MgIgeAU9tvE3gsDcC/A+eT4f/w3OWYv+oTeKDq4ESdxlAfax08Rul4eopIICROT1k5\n9lbNxSXVngsOHMBlBfmYbTLjjJgYPF9ZgZWN/ineF9tsqJUkLNy/D2/WVONOd+yR47TIMj6tq8fl\ndn8p2SUOJ/5QVIS/VJTjOrtT+/gHzDZ1o6dPqy3XDbamvgpjUDsELZaWh3zlKhf2+tRyjYjeBbAO\nwElEdIiIbmz33IUANjHGihljtQDWEVEuAMYY23bcobYD8BHRNiL6H/hnq4iB7bMAXNfuhuVhYwBs\nIKJtAL4D8CxjLLfd8w8DeIz5P7UuAzAVQC6Af3b5mtS+EnNC6uy5AK6fNmK+9ZQR8y5WOp6+8rbW\n1ibvfr9pbPW2wcE+tgzG3pkgF36Wpk/p7b7kkz2vFZQ2ThV8QSlKtbXJWXyh+EJiT7fnKzGj1oiM\nrOx9SgehNFVfgQfmfp8FoG5o/NiwmX3SF1qD3V468ZbByybfU1JiTAhq8ScBRFfniim/frO1oLcz\nVJhG0N2WECdUMxx/RdIn443V8Qa5kZeY5SL2YiuYVJ3AAcQDGGIzub32mNjhSgcTDFpbSsKO6Q84\nVp50fWGDaArq8vYzijUpS//uLda1yL1KoG0mjf0KW2ylHIRPexoB4nzPGj6dkOMJHDyBnwJAHp00\nZaRAQtT8LogEQsLUIetnPS6uTz433wtBCtaxxzSIg5950Vtnr5Qau9/6qGKXcfCdOlt+MGJIo5yg\nvR4uYk3LTE9T/dBY1CSt3goUrjoTQFWCI3WY0vGEgqjR6ZuHp6WunPlY4w7nyUG7mZjgFd2Z/5Iw\nZL+vqjf7rRhsS3mHGfpdfna2qcDJQlN2hYscBOBXSgehNNUmcADJABwAmp2WuKhM4IdpDTZb6cSb\nk5ZNvqe02JTYq6TbGYssxDyRxSxTNvVihgoRPZnsdufJYl1/zm3TSjETPbm8uBV3ttIBKE3NCXwE\nACS7R8bqNIYYpYMZCFpbyqCd0+53rjzp+sJ60dzv8XEdSHfPcko876u2Hs/3ZlpBf/2gOF+djH7d\niFzMVjX1Z38uKszNTE8Tu98seqk5gU8F0DA0fmxUX30f7/D4+IbZj4nrkhfleyH2azxZANGSrWLK\nrf9uLYDcsxkqLWat6yqbu7Q/5z1Ln3f84gpOfazw38dSLVUm8EDtk1EA6uLtyVEx+6S3RFGnbxl+\nXurKWY82/uya0u/x8flFmpQ/veQt1rb2bIZKgduU/IDG0ueVmkMNTbFOqSJkTSS4iHFC5T81UWUC\nh7+eL0RBA7vZ3evFKdFEq7fZyifcmLRsyn2lRabB/RpXHheYoWKrlno0vPF5kn3Ip0zXpytxImCR\ndzkfB+d4Aleh0QDYiISJSaKg0XW7tQporcmDdk27z7Vi9I2F9ZqYPl/ZJnpEd+Y/JTn5gK/7xURE\n9HBSnHWvLPSprdsicZNa//1yR83JTE/TKh2EUjTdbxKVpgKoHRI7aqrSgYQTIoEwaMqQDbHjPeaC\nFfnTCr9K1kLq9U0iqyxYnniPtWUu8BRvPUXX5bJ3WSeYromLq1heUWI0E/Xq3+MUU1mc6PHIEulU\nm8i9koSXVq2DT5IhM4aJSQlYOH4U9pRVInvbTvhkGUkOGy6bNhFiB0sdappa8MGP21Hb3AIQ4aa5\n0+A0m/D2+p9QWteAMQlxWDRxNADg27w9SLBbMH5wSIoB9pUZwDQAOUoHogTV/cOfkDrbCiARQGOs\nNVFVNzB7ShR1utZh56aumvVY08/uU/o0Pq4H6e/9hgad+3X3M1QaLbrYa83uHvcBPcwgMt2pnnVl\nfYkvWmgEAbedPhMZC0/DnQvmYldpBfIrq/Hexm24etZk3H3O6XCYjfgxv+O/xnc3bsUZJw3DPeee\ngT/MPxUxej2Ka/0FHzMWnoYDldVo8XhR39KKwuracEveh6l2GEV1CRzAMAAQBa0QY7QHvfBTNNHo\nrdby8TckLZtyf9khc1Kvx5tFkHD9T2LKzf9pLWBy1wtvdsebhzwuxPT6puZirO1TzfJoQUTQa/0f\nXCSZQZZlEBE0ooBYi3927Kj4WOQeOvFWQ2ldA2TGMGqQvzqlXquBTiNCFAheSYLMGHwyg0CEZT/v\nxjnjT+hREC54AleR8QC8Sa5h7mhaPh9KWmtS/C9T73WtGHNzYZ3G0uv512cf1KQ8/LL3kLZV7rLF\nz3vJjqRvZW2v6pycbtir+iYPsszw3DdrsfSzbzEy3o0hTjskmeFgdS0AYPuhEtS2nNjMqLKxCUat\nFm/88COe+2YtPt+2E7LMEG+1wGEy4q/ffo9JyQmobGwCAzDYEba/6hmZ6Wm968IdJdSYwCYDqIm3\nJ8crHUgkIRKI4k8esmnWo9qcIYvzPST2qt/ahDox6akXvTXWGqnzG6QCiXcnxZkLZaHHbxJxeo99\nqHdvbW9iiTaCQLhzwVw8lDYfB6trUVrfiKtnTsZnW3fg/5Z/D71GA4FOzG+SzHCgshqLJ43FH846\nFdWNzdiUfxAAcMHkcbhzwVyccdIwfP3zbiwcPwrLd+zBv3O2YP2+kPSt7o8YBGaWqY2qEviE1Nlm\nAE4Arc6YeJ7A+0AQtbrWYeekrp75eHOue9rB3uyb5BFjM1+RfEkFnc9QkfSi+Sp3XGOr3PNiJ4ul\nFf1amh8tjDothse58EtJOVLdDvzmzNn4w1lzMCzWCXeM+YTt7SYDEu1WuGJMEAUB4wfHo6jm2IZH\nPxeVItlpg8cnobSuEdfOnoLNBUXw+MKunljY9bIdCKpK4PCXj5UAwGpyxikcS0TT6C3WivHXJS+b\ncn/ZQXNyRU/3s8mC9X/fYeZJP3lLOtum1qaLv8nk7PGbwwLtNn33W0WnxtY2tHj8a6e8Pgl7yioR\nZ41BQ6u//LpPkrBq1z7MGj7khH2THXa0eLxoDGy7p7wK8dajVSUkWcbaPfk446Th8EoSDl/EMzBI\n3dzTUMB4pQNQgtqmEcYh8KZlNlj5FXgQaK1J8bun3ovd5dsLT9n7ntPure+2rowepL/vaxb/RkVb\nwbIFHXf52ZZgSflrflvhHaz5xMxznDHG2jhzS31bk2hVXSKvb23Dexu3gTEGmTFMSk7E2MR4fL5t\nJ3YWl4EBmDU8BSPj3QCAg9W1WLevEJdNmwhBICyeNAb/+G4DGIAkhw0zhh39df+wtwBTU5Og04hI\nsFnAGPDssjUYPSgWRl3YTb1WZQJXVUu1CamzLwdwZozBVn31GXffq3Q80UaWvF5j4cqiaYVfJumY\nr0cXB8tSfPmvXq5L7fB+ssR8f88vqZ0j+NzdHecPtZcf+tRwftLxj/OWaqqRm5GVHdFdtfpCbUMo\nwwE0JrmG8+GTEBBErbZt6MLU1TMfa9keO71HQyALCzSpf3zZe0jT1sEMFZE0vx8cryuVqaW746QJ\n69RzJcJ15KTM9DS1jSioJ4EHGjgMAdDktg3mwychpNFbLJXjliQvO+XB8kJzSrfTAif5Z6hUWzqY\noeI1iNYrnHG13m4+Ks40HXLxJg+qpgNwktJBDDTVJHD4mzdoAUgOcyxP4ANAa0mM2zP17rjlY289\nWKu1dtmCLblNjMt8RfIlFvpqjn+u0qFP+LXB0eUiH4tGMp3i3dLjm6lcVFLdOLiaEng8ABkAYoy2\nWIVjUQ0ighA3MfnHmY/qv0+9MN9Dmk7nj9tlwfrk28w0YeuJM1TWJ1pT/wljl8v60+TveJMHdRur\ndAADTW0JXAAAvcZoUTgW1RFEjdaTenbq6lmPt2yLm3Gwsw71BpD+ga8QP//bthOS9fPJrrhNsqbT\nOeTz9TtV0VmJ69QJN7GjnZoS+AgArQCg1ej4f3SFaHQxlqqx1yZ/O/Wh8gJzSodDHiJIuPVHMena\nd1pL2tdQYRpBd1tCnFDF0NbRfinGZne8r7jLoRouqoVlpa1QUlMCTwTQYtCatKKgCbtJrGqjtSTE\n7Z16d+zycbcdrNHaOqwHnlagSbj7H21VmlbpyOW6x6SxX2GPq+zsCn6Rb0X3dci5aMUTeBSzA/DY\nzW5+9R0miAhC7ITkzTMfMXyfelF+K2lOWJ89vVbreuQlb7Olxndk7LzEaRh8h86e39Exz9VsVnWT\nW5XjCTwaTUidTfA3QPVYTM4Ti0JwivKPj5+VumbWEy2bY6eXSsddXY9o05ifeEWSB+d7j9ykXDXY\nmvo2DCfUEJ9krIjTSi18PqE6xamtKqEqEjgAEwACwGIMNn4FHqY0OnNM3bglg76d+seqXebkY+qf\nxsui7rF3mWHS1jb/EAkRnkpyu35m4jGVCPUi085p4bNRVEoDoNtVu9FELQncjMAUQrPewhN4mNNZ\nEl3F0+4zZJ90XWOZznbkhqUZgnjPV4Lj3OWtxQDAtIL+hvg4uVaGt/3+C1hO2JXK4waMqoZR1JLA\njyRtg87Mh1AihClhWsz2GUu1X6csamgRtF4A0ILo+k2axFvebSkAgBaz1nm11X1Mu5kzYgqMSsTL\nhQWewKOQGf4hFBh0Jn4FHkFEUSfohp5nWTV9Ka1LnFkiwz8+fla+NuVPL7cc1HhkqSDWlJwhW46s\n4EwwevUnteTyYRR14gk8CsUgkMD1WiO/Ao9ABoNd0zLqmoQvpj9Yt9s+rAwAxtVokzNf8FRa66WW\nb4ba7f9pMx5J2ou8Kzrv/MNFM4fSAQwktSTwIysvNYJWdTWjo4nZNNh26OSM+M8n3V5SrLd6E9o0\n8c/93dc2uFiqeybFZdgpaRsA4CxDnk7pWDlFqGqNh1oSuBuABwCIOmgOyEUcs2N8Qt6MR4Qvhi9q\n0sFgfvItWT92l7f1Gnc8q5chj45pstp8NSd28uWinapKyqolgduBIzMVeAKPEqKgFY3J55lXzlxK\nOxPnVN7/tWCcuUnCZdpBDaIAWuT5llcnVB+ewKOQBgAv+B+lDDq7pnrUVckrpz9Ue8aeobpT1wrs\nfp+tcpG4QenQuIHHE3gUoqPf8CGUaKU1JTjLJt9tECy36GJ/SPJVaevU1TOQA1SWwNXyYgn8Clw1\n7LGTTJJrnGFXQc5+G1snqOy+ltqpJacBUM8V+FHEx8DVQBQ0gsVx2gij8Rwz473W1IQn8CjU7nXy\n/K0mVsuk+CY5pVDpOLgBwxN4FDoyhEI8g6uO231JaqNHV6R0HNyA4Ak8CrVL2vwmphrZXEvcbT65\nTuk4uJBT1QpctSRwTuW0GoteNJ3vlWXWaVNlLiqo6k1aLQn8yFW3T/by1XkqFWMe5W7BmBOaQHBR\npbb7TaKHmhI4AwCPt1VVH7G4Y7lci4Y0eMz8pmb04gk8CnkReK1tvhZeZlTlHO4lia1eVqV0HFxI\n8AQeheoQWM3R5m3hV+AqpxENGr3lUlGS5bbut+YiDE/gUagWgQTe6mnmCZyD0TjE7hGm8mJX0Ycn\n8ChUjcD80Ja2Rj6EwgEAHI4zkho8jgKl4+CCis9CiULNCNzEbGqr51fg3BHO2KuTm71UrnQcXNDw\nK/Ao1IRAAm9s5QmcO0oUtILJdqXRJ8n830Xka83IylbVJ2y1JPAjV+D1zdWq+gvmumfQx1sk7Wl1\njJeejXT7lQ5goKkpgRMANLbWtcpM5tXpuGPYbNMTmqREPh4e2fYpHcBAU0sCb8KR1ZgMXp+nUdFo\nuLDkdKWnNHlEvlIzcu1VOoCBppYE3oJ2y+lbPI3VCsbChSlBEMjiWOLw+OQGpWPh+oQn8GiUm58j\nwX8VrgWAxta6SmUj4sKVTmc3kvHcVpk3gYhEPIFHsXIABgCob67mCZzrlCVmXGyzPPyg0nFwvcYT\neBQrBGACgJrGcp7AuS653RemNHr0h5SOg+sxLwDV3YRWUwIvAKAHgNLaQp7AuW7ZXdfFtflYjdJx\ncD1SkJGVLSkdxEBTUwKvQGAueEVdUZ1P8vJCRlyXNBqzTmO+UJZk5lU6Fq5bqhs+AdSVwKsQSOAA\n0NRWX6ZgLFyEMJuGu9poQqnScXDd2qZ0AEpQUwKvhH8qIQFAfXMN/0/J9YjTuSC5wWPhTSDC23ql\nA1CCahJ4bn6OF0AJjt7I5FfgXI853dcObvGC3zsJX+uUDkAJqkngAfsAxABAWe1BfgXO9Zgo6kWj\n9XKdjzeBCEf5GVnZqrwgU1sC34vAXPCCil/KJFniN6e4HjMYEq0+cVYlr3kVdlQ5fAKoL4GXAZAB\nwCd5pPrmar5Yg+sVu/3UwY2+2Hyl4+COocrhE0B9CbwE7V5zRd0h1ZWf5PrP5b4ypdkj8CG48MGv\nwNUgNz+nAUAxAuPgBRW7DygbEReJBEFDZsfVFq8k89ryymsF8JPSQShFVQk8YAsAGwDsL8sr8Une\nVoXj4SKQXuc2M/38Bt4EQnFbMrKyVXsvS40JfBcAEQAYk1ltU6Xq6idwwWG1TB7UJA3h88OV9YPS\nAShJjQk8P/AnAUB53UE+Ds71mdN1cUqTR1ukdBwq9pXSAShJdQk8Nz+nCf4kbgGAA2U7+Tg412eC\nIMDqutbl8cn1SseiQvUAvlc6CCWpLoEHHBkHP1i5p8Lja+Mt1rg+02psBsGU5pEZU101PIUtV/P4\nN6DeBL67/Q81jeX5CsXBRYkY82h3CzuJ1w8fWF8qHYDS1JrAD9+4FACguPrAHgVj4aKEy5WW0ugx\n8ZuaA0MG8IXSQShNlQk8Nz+nDcAeANbAz7skWfIpGxUXDezuJQmtXsabZofeuoysbNUvplJlAg/4\nEYEbmc2eRk91Q+nubrbnuG5pRKNWb7lYkGTZo3QsUe5jpQMIB2pO4DvR7vXvL8vLVTAWLooYjal2\njzBFldXxBtBHSgcQDtScwIsBFCFwFZ5bsH4PX5XJBYvDcWZyg8fOF4mFxtaMrGw+/RcqTuC5+TkM\nwCoADsBfnbC87tAOZaPioonTfXVSixflSscRhd5UOoBwodoEHrAV7dqs7SnexodRuKARRZ1otF1p\n9Elyi9KxRAvGWBuAt5SOI1yoOoHn5udUwT8bxQ4Au4q2FLR5W/mKOi5oDPpBFkk7t4YXvQoOIvo4\nIyu7Suk4woWqE3jASgSmEzIms9KagjyF4+GijM02I7HRN4jPDw+OV5UOIJzwBA7kAZAQ+F3sKtq8\nXdlwuGjkcl8xpMkjligdRyRjjO2H/4KLC1B9Ag80edgOwAUAB8p2lDa11vMpYFxQCYJAFsc1Nq8k\n87o7fUREr2VkZfOhqHZUn8AD1gIwHf5hT/E21fbY40JHp3OaoF/YxBiTlY4l0jB/obDXlY4j3PAE\n7rcTgBeAFgA27V2Z2+ZtbVA2JC4aWSwT4pvkobyZdi8R0ZcZWdnFSscRbngCB5Cbn9MK/9haPABI\nslcuKN+5QdmouGjldv8qpdGj55ULe+efSgcQjngCP2ol/K3WBADYsPvbHyXJx+tZcCFhc10b2+Zj\ntUrHEQkYYzsAZCsdRzjiCTwgNz+nHMAmAHEA0NRW31ZUvX+LslFx0Uqrseg15gskWWa8CmY3iOh/\n+c3LjmmUDiDMfA1g+uEffty7cn2Se8R0gYSIf6OTZQlPf/Rr2Mwu3H7uE3h79TMorNgNBoY4WxKu\nmXcv9FrjMfts2rMcy7e9f+Tn4qr9uPfilxHvGIJXvn4YtU0VmDvufJw27gIAwDvfPYe54xYj2T1y\nQF9bpDKbRriqW8cXmpA3ROlYwpXM2AGB6F2l4whXPIEf6wCAvfBfhVeX1x2qq6wr3hFnTxqvcFz9\nturnjxDvGIJWTxMA4Fezfw2jzgwA+DDnJXz38ydYMPmKY/aZNvIsTBt5FgCgqGo/Xln2MJLcI7A9\nPwfJsSNx+6In8NSHt+G0cRfgUNU+MMg8efeS07lwSGVZQWGMrpEn8Q4IRE9kZGXzVnWdiPgry2AK\nFLj6DIEKhQCw9cDaHOUiCo6axgrkFWzA7NGLjjx2OHkzxuCVPCDq+hib967EKSPmAQBEQYTX1wZZ\nPvr/KnvT6zhv6nVBj10NHO4liS1e8OXhx5EZKwIvXNUlnsBPlAegEkAMAOwvyyupbarMVzSifvow\n50VcOPMW0HFZ+q1VT+OBty5BWW0hTh93UZfH2LJ/NaaOOBMAMDppKupbavDsx7/FWZPSsT0/B0Pc\no2A3u0P2GqKZKOo1ButlGkmW25SOJZwIRE+qvWlxd3gCP05ufo4E4BMEVmYCwNb9a1YpF1H/5Bas\ng8XowJDYUSc8d828e/D41e9jkD0Fm/et7vQY+WU7odUYkOgcCsB/BX79/Adx3yX/wJRhp2N17oeY\nP+lSfJjzEl79Zim250f8h5YBZzQk2bzijAql4wgXMmPl4HVPusUTeMc2A2gBoAeAXUVbCivri3cp\nG1Lf7C/NQ25BDh5++0q8vvwx7C7eijdXPHHkeUEQMWX4Gdh6YE2nx9i8bxWmDp/X4XNrdnyK6aMW\nYH9ZHjSiFjec9RCWbflP0F+HGtjtc5MavC7eBAKAQPR0RlY2b7DSDZ7AOxBY2PMFgEGHH/th55ff\nykyOuCXQF8y4CY9dnYVHrnoH15/1R4xKPBnXnnk/KuqKAPjHwHML1iHe3vE9NJnJ+Gn/d0fGv9tr\nbmvAzwXrMWPUAnh9bSAQQASvxKfP95XTfVVys4dUXYtHZqwCwMtKxxEJeALv3CoATQjUSCmpya8+\nVLl3o7IhBQcDw1urnsLjH9yEJz64CfXN1Tj3lGsAANvzc5C96WjJib0l22E3x8JtTTzhOF9tfgvn\nTLkaRIQxSdNQWLkbT3xwE2aPOW/AXku0EQWNYLZfZfZKcrPSsShFILonIyu7Sek4IgHxOvOdm5A6\new6AmwDkA4DF6DCmz/n97zWi1qBoYFzUq6/fXKL1rR5Ex995jnI+Sd6mEYXJfOFOz/Ar8K6th7/x\nsR0AGlpqWvaUbPtO2ZA4NbBaT0lokpJUNR7OGGOCQLfw5N1zPIF3ITc/xwfgHfgbHxMAfL/ji40t\nnqZqRQPjVMHpujS1yaNRTQU+ryS/f/f7X0TFMOVA4Qm8ezsAbEOgRooke+Xc/HXLlQ2JUwNBEGBx\nLnF4fHLU92mVZblZpxHvUDqOSMMTeDcCqzPfB2CAv1ohtuxfvbOuuYr3OORCTqe1GQXjojbZ39Ag\nakmMPZaRlV2qdByRhifwHsjNzzkEf7nZhMOPrdv19VeROK2QizwxMWNjW+SRUVs/3CfJhVpRfFbp\nOCIRT+A99zkAGYAOAPLLd5buL83rfPULxwWRy31+SqPHEJWdfASi2/mS+b7hCbyHcvNzagF8BODI\nhOhVuR+ubWipVc1NJk5Zdvf1g1p9rEbpOIKp1ev7790ffPGl0nFEKp7Ae2cl/NMKXQAgyT55Td6n\nn8iyFNXjk1x40IhGrS7mV5BkFhVXqx6fVGnQam5QOo5IxhN4L+Tm53gAvAJ/pUItABys3FOxp2Tb\nSkUD41TDZBzqaBNOjgtDQ/QAABCaSURBVPibfYwx1uTxLMnIyubNw/uBJ/Beys3PKQDwIYDBhx9b\n/fMn6+qbq6NyfJILP07H/ORGrzWiF/nUt7a99djnK/jQST/xBN43y+BfXh8LAIzJbFXuR59IshQV\nH2258OdwXZvU4kVElp9t9XoPEXCz0nFEA57A+yA3P8cLf61iAwKzUkpq8qt/KdrMF/hwA0IUdaLR\nerneJ8kRVXJVZkxq9ngv+fNny3nJyiDgCbyPAnPD30e7oZQ1eZ9vrG2qPKBcVJyaGAyJVp/21KpI\nKkhX39L6l8ezV25QOo5owRN4/6wAsBuBZfYAw7db3/vY42ttVDIoTj3stlmDG33x+UrH0RPNbZ4d\ndpPxXqXjiCY8gfdDoNjVv+AfRtEDQFVDacPavM+z+NRCbqC43JenNHmEsJ6Z0ub11Te0eRZmZGXz\n1ctBxBN4P+Xm55TCX7FwMAIVC/eUbDuUW7D+C0UD41RDEDQU47jG6pXksPzkJ8myVFRbf8XTX62O\n2nIASuEJPDhWA/geQPLhB9b98tVPB6Okgw8X/vQ6l4npz25ijIXdFW5BVe1TL67M4VMGQ4An8CDI\nzc+RAfwbwEEcGQ8Hvt7yn2W1TZX5SsXFqYvVMim+SU4JqyqZxbX1X63+Zf9DSscRrXgCD5JAI+Tn\n4S94ZQX8S+2/2vzWB63e5lpFg+NUw+2+JLXRoytSOg4AqGlq3r0p/9DFeUWlYfepIFrwBB5Eufk5\nlQD+BsCJwE3Nuuaq5tW5H73HF/lwA8XmWuJu88l1SsbQ7PHU/FJWuWDNL/tblIwj2vEEHmS5+Tm7\nAbwB/01NAQDyy3eVbdm3+hMl4+LUQ6ux6EXT+V5ZZj4lzu+VJM/+iurLPti0PaKX+0cCnsBD4zsA\ny9Hupubmfat27CnmRa+4gRFjHuVuwZgBL3UsybK0t6zqrte//5GvSh4APIGHQKAN23vwL/I50sVn\nxfYP1h4o27FWscA4VXG5Fg1p8JgH7KamLDM5r6gsc93+whcG6pxqxxN4iARKz/4dQDP8Y+IAgGU/\nvbOysGL3esUC41TF4V6S2OplVaE+D2OMbTtU8vaPBUV/zCsqjZy1/RGOJ/AQCnTxyQSgAWA//PiX\nm/+9rKhq34+KBcaphkY0aPSWS0VJlttCdQ7GGHIPlX7yU2Hxr/OKSvnN+gHEE3iIBYpePQ3ACMB2\n+PHPN73xRWlNwTbFAuNUw2gcYvcI00JWenZHSflXPxYUXZdXVBqWK0GjGU/gAyA3Pycf/iQeA8Di\nf5Ths42vfVpedyhPucg4tXA4Tk9q8DqCPivkl9KK1Rv2H7w6r6i0PtjH5rrHE/gAyc3P2QfgWfiH\nUmIAQGYS+3TDqx9V1pfsUjQ4ThWc7quTm71UHqzj7SuvWv/D3oLL8opKq4N1TK53eAIfQLn5Ob8A\neA7+psgmwL9a85MN//xvdWP5XkWD46KeKGgFk+1Ko0+Sm/t7rN1lleu+233goryi0ojsChQteAIf\nYLn5OXkA/gJ/zRQjAPgkj/Txun+8V1FXtEPR4LioZ9DHWyTtaXWsj10gZMbkrYXFq77fk39ZXlFp\nWJewVQOewBWQm5+zHcALAAbB35YNXqlN+mj9P/7LKxhyoWazTU9okhJ7PR4uybJv/b7CZVsKi2/M\nKyrlpWHDAEVSO6ZoMyF19iwAtwIoh3++OADgzImXzBmVePJ8xQLjop4sy6ym4vkSs05K7Mn2Xklq\nXbP7wGcFVbX35BWV8iXyYYIncIVNSJ09GcBvAdQBOHInf+aohZMmDj31fIEE/imJCwmPp7alte5V\nn04jWLrartXrbVy5a/97pXUND+YVlQbtJijXfzyBh4EJqbNHArgTgA/AkVVzY5Kmps4es+gyragz\nKhYcF9UaGvMqRM/XLoGowwuFxta26m937P1XTXPL43lFpYpWOOROxBN4mJiQOjsJQAb8Y+Jlhx9P\ndA5znX1y+pVGndnZ6c4c1w+VlZ8UxIj7U45/vKqxuWTFzr1/a2zz/F9eUSkvCxuGeAIPIxNSZ7sA\n3AEgEf7uPgAAi9FhPG/qkv9v705joz7OOI5/57/r3bXXx/oAY5tjwWBwYblzLSGkSYAkbaUiNYnS\nI03VqFJfVqnUF1FfVFHVV1WPKG3yplUi1DZpRaSkKGcDSekGHAiWF4wxEBaf+FofeG2v95i+mDUY\nh8M24PXaz0f6y7CXx3j98zDzzMyTHneJN11tE3Nbd8fLLbmO6OKxv5/t7Dlx6Ezo90mtX5fl8bOX\nBPgs4/P6c4DngM2YEE+AqeHdufGph5YtWL1NKZXOJoo5KB6PjEZ6X4nYLe3+/HzLZ/XtnS8Bb8lp\nOrObTJDdAqXUE0qpk0qppFJq67jbtyml6pRSnyulVqZu8yil3lc3Sd9gKDAE/Al4H1gGOAASyVjy\nvS/2fvS/U/v3jsajkTv3VYn5yG53O6L2HQPvnWjcX9/e+Stgn4T37Cc98ElQSjmALK11ZMLt1Zgz\nMF8Ffq61Ppq6fR/wC8ALPKq1fl4p9Vvgba31J5P5nD6vXwE7gB9iKlQun6tZ6F7g3rXp6T2FuQsr\nb/mLEwJo7gqe/uDYHz+OxiK/O9l68Uy62yMmR3rgN6CUqk4F72mgauL9WutTWuvT13hqDLPKMgeI\nKaUqgYrJhjeYQyGCocBB4NeYYZTFgALojXRF3jj00t7Trcc/Suqk9JLEtMUSo4lPg6+ffefwb16L\nxiIvSHhnFumBT6CUcgNPAj/GBOZfgTe01pdu8JyDXN0D3wi8AgwDP8BsYvVLrfW0fjh8Xn9u6nXu\nA9qAkbH7Vpb5Ku6v/tZ3XI4cz/WeL8S1DA73d31Q+7fPOsL1B3Sy52WZrMw8EuATKKUGgDrgOa31\npHYJnBjgE+57APg2JtBfxPTOn9dad0x87I2khlS2A89gArx77L4cZ57z0U3f++ZCz+J1U3lNMT8l\nk4n46dbjXxw69e/aRDL+52AoUJvuNonpkQCfQCm1C9P7Xg/8HXhNa33DpcPXC/DUhOX7wFOYvU9e\nxIyLb9davzCd9qXqxX+KOWuzBTMGD8A9VbvWr1t67+4suyNnOq8t5r6+SPeFj+v+dayzv+UL4NVg\nKNB90yeJWUsC/DqUUsXA94EfYXq7z2mtQ9d57EGuHeDPAgVa6z8opd7iysTmY1rrn023bT6v3wU8\nAezELPq5PLma6/K4vu7b83B50YotN6t4EfNHPBEbqQsFAjVnPmwG3gHeDoYCMmSS4STAJ0EpdTfQ\nrrVunnD7HuAlYAGmSqRWa707dV8OsB/YpbWOKaW2Y8oDR4GntdaNt9Km1JDKRuAngA1oBy5/MysX\n+crvXb37G3nZnkltViTmrs6+loaP6t6sGxgKnwb+kjohSswBEuAZLrV682ngLsw+Kpc3xFLKUtvW\nPL5lzeItD9ttWa50tVGkRzQ2MlBz5sPAyaYjbcCbwMfS655bJMDngFRvfC3wLOa0nzbMZCkAHneJ\n+8F1e3aWepZukFGVuS+ZTCSau88cPxDc1zgSG6oFXg+GAlOaNBeZQQJ8DvF5/U5gF6bqJQZcdWLK\n6orNS+9e9cjjbld+aTraJ+4srZO6vbep9lD9Ow3hwY4+YC9wOBgKyFqBOUoCfA7yef2LgO9ixsi7\ngMs17EpZakvlg1+rXnLXA25n3sJ0tVHcPlprugZaTwYa3j16sfeCAgLAG8FQoO9mzxWZTQJ8jho3\nyfkMUIAZVolfeYRic+WO6rVL7t4hPfLM1XPp4pkjpz843NTdqIFW4G/AyWAoID/Y84AE+Bzn8/qz\ngceBx1I3XWRCkG9a8cCatUvv2ZHryl808y0U09Ef6bnw+dn/HDrbXhfHlLn+AzgeDAUSaW6amEES\n4POEz+svwtSN78RsEdDOVUEOG5dvX71u2b07cl0FZWloorgJrTV9ka5zwQuHj9Y31wxjKo7+CRyR\n6pL5SQJ8nvF5/YXAI8BuTJBfZFzFCsAG7/1V1Uu23leQU+yVqpX0iydiI23h87XHv/y0tr035MTs\nsbMPOBQMBaJpbp5IIwnweSoV5A9jgtziGkFeVugtWu/dtqmieMVGh92Zm4ZmzmuRkYGOcxdP1Bw7\nd6AxGhsuwnx/3gYOpPaNF/OcBPg85/P6PVwJchumamVk/GNslt1a791Wtaps/ebC3IUrZYn+nZPU\nyWRXf2v9yaaamsa24xEgDxgE3gP+GwwFBm78CmI+kQAXAPi8/gLgAUwdeS4whJkcu+oNsiC/PH/D\n8u2blpSs3OTMyi6Y+ZbOTZGRgc628PkTx84drOuLdLmBLOAM8C5wQsa4xbVIgIur+Lx+O1ANPARs\nwAR4DybQL1PKUuuW3lO5onTt2uL8slUOu9M9863NXFprBkf6WtvCoVMNLcdOtfeGRoEizOEdB4FP\ngFYpBxQ3IgEuriu1z8pdmF55IWZopYtxW9gaipVl6ypWlK6tWuhZWiXliNemdVL3D4UvtIW/PFXf\nfLShe6BtGLP1gRPz77ofOBoMBeTMUzEpEuDipnxevw1zpNyDwFZM9cogZgfGryzTLs4ry1uzeHNV\nedHyKo97wQqbZbPPZHtnk0QiPto/1HOhpedcw8mmmob+oe44UIKZb4gBNZiVk42y5F1MlQS4mJLU\nWPl6zPFuqzFhPgqEUx+v4rS77GsWb11RXrzc63GXVOS6Cspslj1rRhs9g6Kx4f6+SHdT10Bbc0v3\n2eamrsaOpE44MaFtYYaiDgPHgLMyti1uhQS4mDaf158DrAI2Y3rmY1vW9mJ66F+hlKUWF1eWVBRX\nVpTklZUXuIsr3K78UktZtplp9e2T1MlkZGTgYu9gV3NHX1NTqLOhuedS+yXMLzU3ZthJYRbcHAJq\ngfOyWlLcLhLg4rZIDbMsxWxrex/myDcwvfJLmJ7nNd9sdpvDtmxBVWlZobe8KK+0LNuR63E5cjxO\nuyvfmgXDL7H46NDwaCQ8FL0UHhzpDw8M9YTDgx3h5u6zndHYcAwzHJKPqd6BKytdj2DOV22S4RFx\nJ0iAizvC5/WXACsxY+fVwNjOhwozGTrAhHrzr1IUukvcRXmLCjzuEk9etqfA7covyHbkFrgcOZ4s\nm9Nts2xZlmVzWMqyptK+RDIeSyTj0UQiHo0n49FEIhaNJ+PRWDw6PDjS39s/1BMOX+oId/Q1hyPR\ngYmrHV2YwB77H0ccU/IXBM4DzbLQRswECXAxI1KbapWnrmpMsBdjJkHHQn0EiGJ67VN6Y2bZnLZs\nh9vhzHJl2Sy7zWazW5ayWTbLbrNZNms0Ho2NxIZGh6OD0aHoYDSpEzd7fQvIHnepVFstzC+fE0A9\n0Ay0B0OB+HVeR4g7RgJcpI3P68/DBPoSzPBLKaanXoAJ8LE3p4Wp2IimrjimXjrB1ILeAuyYIY+J\nH53jPudYWHdgtuFtSv05nLr6pD5bzAYS4GLWSS0myscE+dhVBizCVHO4McMXTq6E7URjb2yVuixM\nz344dQ2lrghXVp2OD+kBGbcWs50EuMhYqUMr7IAD04u2YYJ67FJc6bVHpfpDzDUS4EIIkaGmNHMv\nhBBi9pAAF0KIDCUBLoQQGUoCXAghMpQEuBBCZCgJcCGEyFAS4EIIkaEkwIUQIkNJgAshRIaSABdC\niAwlAS6EEBlKAlwIITKUBLgQQmQoCXAhhMhQEuBCCJGhJMCFECJDSYALIUSGkgAXQogM9X8Z/Zeu\nbLd+GwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def draw_seg_dist(usr, usr_segment, total_segment, total_usr_segment, usr_graph=True, total_graph=True):\n",
    "    if usr_graph:\n",
    "        x = []\n",
    "        y = []\n",
    "        less_1 = 0\n",
    "        between_1_3 = 0\n",
    "        for seg in usr_segment[usr]:\n",
    "            percentage = (usr_segment[usr][seg]/total_usr_segment[usr]) * 100\n",
    "            if percentage >= 3.0:\n",
    "                x.append(seg)\n",
    "                y.append(percentage)\n",
    "            elif percentage < 3.0 and percentage >= 1.0:\n",
    "                between_1_3 += percentage\n",
    "            else:\n",
    "                less_1 += percentage\n",
    "        x.append('< 1%')\n",
    "        y.append(less_1)\n",
    "        x.append('1% to 3%')\n",
    "        y.append(between_1_3)\n",
    "        \n",
    "        fig_size = plt.rcParams[\"figure.figsize\"]\n",
    "        fig_size[0] = 5\n",
    "        fig_size[1] = 5\n",
    "    \n",
    "        labels = x\n",
    "        sizes = y\n",
    "\n",
    "        fig1, ax1 = plt.subplots()\n",
    "        ax1.pie(sizes, labels=labels, autopct='%1.1f%%', shadow=True, startangle=90)\n",
    "        ax1.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "    if total_graph:\n",
    "        x = list(total_segment.keys())\n",
    "        y = list(total_segment.values())\n",
    "#         print(len(x))\n",
    "#         print(len(y))\n",
    "#         plt.bar(x[0:100],y[0:100])\n",
    "        y.sort()\n",
    "        _, ax = plt.subplots()\n",
    "#         ax.set_xlim([18500, len(draw_list)])\n",
    "#         ax.set_ylim([0, 500])\n",
    "        plt.plot(np.arange(1,len(y)+1),y)\n",
    "\n",
    "#         x = []\n",
    "#         y = []\n",
    "#         less_1 = 0\n",
    "#         between_1_3 = 0\n",
    "#         total_count = sum(list(total_segment.values()))\n",
    "#         print(total_count)\n",
    "#         for seg in total_segment:\n",
    "#             percentage = (total_segment[seg]/total_count) * 100\n",
    "#             if percentage >= 3.0:\n",
    "#                 x.append(seg)\n",
    "#                 y.append(percentage)\n",
    "#             elif percentage < 3.0 and percentage >= 1.0:\n",
    "#                 between_1_3 += percentage\n",
    "#             else:\n",
    "#                 less_1 += percentage\n",
    "#         x.append('< 1%')\n",
    "#         y.append(less_1)\n",
    "#         x.append('1% to 3%')\n",
    "#         y.append(between_1_3)\n",
    "        \n",
    "#         fig_size = plt.rcParams[\"figure.figsize\"]\n",
    "#         fig_size[0] = 5\n",
    "#         fig_size[1] = 5\n",
    "    \n",
    "#         labels = x\n",
    "#         sizes = y\n",
    "\n",
    "#         fig1, ax1 = plt.subplots()\n",
    "#         ax1.pie(sizes, labels=labels, autopct='%1.1f%%', shadow=True, startangle=90)\n",
    "#         ax1.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\n",
    "\n",
    "#         plt.show()\n",
    "        \n",
    "\n",
    "# for i in [4398, 54004, 2342, 54896, 84539]:\n",
    "draw_seg_dist(9898, usr_segment, total_segment, total_usr_segment, True, False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [i for i in user_dict if len(user_dict[i]) < 20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# user_dict1 = {}\n",
    "# for i in user_dict:\n",
    "#     if not i in a:\n",
    "#         user_dict1[i] = user_dict[i]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "86553"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = map(user_dict.pop, a)\n",
    "for i in range(len(a)):\n",
    "    try:\n",
    "        next(t)\n",
    "    except:\n",
    "        print('fail')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32957"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(user_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def daily_user(user_dict):\n",
    "#     user_dict_daily = defaultdict(lambda: defaultdict(list))\n",
    "#     cur = 0\n",
    "#     for usr in user_dict:\n",
    "#         if len(user_dict[usr]) == 0: continue\n",
    "#         firstDay = user_dict[usr][0][0]\n",
    "#         cur = datetime.datetime(year=firstDay.year, month=firstDay.month, day=firstDay.day)\n",
    "#         for i in range(len(user_dict[usr])):\n",
    "#             cur_entry = user_dict[usr][i][0]\n",
    "#             if cur_entry.month == cur.month and cur_entry.day == cur.day:\n",
    "#                 user_dict_daily[usr][cur].append(user_dict[usr][i])\n",
    "#             else:\n",
    "#                 cur = datetime.datetime(year=cur_entry.year, month=cur_entry.month, day=cur_entry.day)\n",
    "#                 user_dict_daily[usr][cur].append(user_dict[usr][i])\n",
    "                \n",
    "#     return user_dict_daily\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# user_dict_daily = daily_user(user_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_dict = defaultdict(lambda: defaultdict(set))\n",
    "# for usr in user_dict_daily:\n",
    "#     for day in user_dict_daily[usr]:\n",
    "#         for i in range(len(user_dict_daily[usr][day])):\n",
    "#             test_dict[usr][day].add(user_dict_daily[usr][day][i][1])\n",
    "    \n",
    "# # user_dict_daily[29][datetime.datetime(year=2018, month=5, day =24)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for usr in user_dict_daily:\n",
    "#     temp = set([0])\n",
    "#     for day in user_dict_daily[usr]:\n",
    "        \n",
    "#         temp = temp.union(test_dict[usr][day])\n",
    "#     print(usr, temp)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_timeslot1(d_time):\n",
    "    slot = (d_time.hour * 60 + d_time.minute)/5\n",
    "    return int(slot) if slot < int(slot) + 0.5 else int(slot) + 1\n",
    "\n",
    "def create_data(user_dict):\n",
    "    input_data = []\n",
    "    c = 0\n",
    "    for usr in user_dict:\n",
    "        c+=1\n",
    "        if c % 5000 == 0: print(c)\n",
    "        for j in range(len(user_dict[usr] )-1):\n",
    "#             slot = convert_to_timeslot1(user_dict[usr][j][0])\n",
    "            loc = user_dict[usr][j][1]\n",
    "            input_data.append([usr, user_dict[usr][j][0].weekday(), loc])\n",
    "            \n",
    "    return input_data\n",
    "\n",
    "# def convert_to_timeslot1(d_time):\n",
    "#     slot = (d_time.hour * 60 + d_time.minute)/5\n",
    "#     return int(slot) if slot < int(slot) + 0.5 else int(slot) + 1\n",
    "\n",
    "# def create_data(user_dict_daily):\n",
    "#     input_data = []\n",
    "#     c = 0\n",
    "#     for usr in user_dict_daily:\n",
    "#         c+=1\n",
    "#         if c % 5000 == 0: print(c)\n",
    "#         for day in user_dict_daily[usr]:\n",
    "#             temp = []\n",
    "#             for j in range(len(user_dict_daily[usr][day])):\n",
    "#                 temp.append(user_dict_daily[usr][day][j][1])\n",
    "# #             slot = convert_to_timeslot1(user_dict[usr][j][0])\n",
    "#             input_data.append([usr, day.weekday(), temp])\n",
    "            \n",
    "#     return input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000\n",
      "10000\n",
      "15000\n",
      "20000\n",
      "25000\n",
      "30000\n"
     ]
    }
   ],
   "source": [
    "input_data = create_data(user_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame(data=input_data, columns=['userID', 'weekday', 'location'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userID</th>\n",
       "      <th>weekday</th>\n",
       "      <th>location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userID  weekday  location\n",
       "0       2        0        10\n",
       "1       2        5        39\n",
       "2       2        5        10\n",
       "3       2        5       178\n",
       "4       2        6        10"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # recode map location\n",
    "# map_dict_time_loc = {}\n",
    "# num_loc_time = 1\n",
    "# for i in df1['arrival_slot and ap'].unique():\n",
    "#     map_dict_time_loc[i] = num_loc_time\n",
    "#     num_loc_time += 1\n",
    "# df1['arrival_slot and ap'] = df1['arrival_slot and ap'].map(map_dict_time_loc)\n",
    "# np_df1 = df1.values\n",
    "\n",
    "map_dict_time_loc = {}\n",
    "num_loc_time = 1\n",
    "for i in df1['location'].unique():\n",
    "    map_dict_time_loc[i] = num_loc_time\n",
    "    num_loc_time += 1\n",
    "df1['location'] = df1['location'].map(map_dict_time_loc)\n",
    "np_df1 = df1.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 0, 1])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_df1[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "500000\n",
      "1000000\n",
      "1500000\n",
      "2000000\n",
      "2500000\n",
      "3000000\n",
      "3500000\n"
     ]
    }
   ],
   "source": [
    "# input_dict = defaultdict(list)\n",
    "# for i in range(np_df1.shape[0]):\n",
    "#     if i % 500000 == 0: print(i)\n",
    "#     temp = np_df1[i]\n",
    "#     input_dict[temp[0]].append(temp[1])\n",
    "\n",
    "\n",
    "# input_dict = defaultdict(lambda : defaultdict(list))\n",
    "input_dict = defaultdict(list)\n",
    "week_dict = defaultdict(list)\n",
    "for i in range(np_df1.shape[0]):\n",
    "    if i % 500000 == 0: print(i)\n",
    "    temp = np_df1[i]\n",
    "    input_dict[temp[0]].append(temp[2])\n",
    "    week_dict[temp[0]].append(temp[1])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data = []\n",
    "y_data = []\n",
    "usr_data = []\n",
    "week_data = []\n",
    "window = 3\n",
    "\n",
    "for usr in input_dict:\n",
    "#     if usr != 29: continue \n",
    "    size = len(input_dict[usr])\n",
    "    \n",
    "    if size == 0: continue\n",
    "    elif size <= window:\n",
    "        temp = []\n",
    "        for _ in range(window - size):\n",
    "            temp.append(0)\n",
    "        for i in range(size-1):\n",
    "            temp.append(input_dict[usr][i])\n",
    "        week_data.append(week_dict[usr][-2])\n",
    "        X_data.append(temp)\n",
    "        usr_data.append(usr)\n",
    "        try:\n",
    "            y_data.append(input_dict[usr][-1])\n",
    "        except:\n",
    "            print(usr)\n",
    "    else:\n",
    "        for i in range(size - (window + 1)):\n",
    "            temp=[]\n",
    "            for j in range(window+1):\n",
    "                if j == window:\n",
    "                    y_data.append(input_dict[usr][i+j])\n",
    "                elif j == window - 1:\n",
    "                    temp.append(input_dict[usr][i+j])\n",
    "                    week_data.append(week_dict[usr][i+j])\n",
    "                else:\n",
    "                    temp.append(input_dict[usr][i+j])\n",
    " \n",
    "            X_data.append(temp)\n",
    "            usr_data.append(usr)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data = np.array(X_data)\n",
    "y_data = np.array(y_data)\n",
    "usr_data = np.array(usr_data)\n",
    "usr_data1 = np.zeros(len(usr_data))\n",
    "week_data = np.array(week_data)\n",
    "# reid user\n",
    "temp = {}\n",
    "count = -1\n",
    "for i in range(len(usr_data)):\n",
    "    if usr_data[i] not in temp:\n",
    "        count += 1\n",
    "        temp[usr_data[i]] = count\n",
    "        usr_data1[i] = count\n",
    "    else:\n",
    "        usr_data1[i] = temp[usr_data[i]]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = len(set(usr_data))\n",
    "usr_data = usr_data1.reshape(usr_data1.shape[0], 1)\n",
    "week_data = week_data.reshape(week_data.shape[0], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for only 1 user\n",
    "# X_data = []\n",
    "# y_data = []\n",
    "# usr_data = []\n",
    "# window = 4\n",
    "\n",
    "# for usr in input_dict:\n",
    "\n",
    "#     if usr == 841:\n",
    "#         size = len(input_dict[usr])\n",
    "\n",
    "#         if size == 0: continue\n",
    "#         elif size <= window:\n",
    "#             temp = []\n",
    "#             for _ in range(window - size):\n",
    "#                 temp.append(0)\n",
    "#             for i in range(size):\n",
    "#                 temp.append(input_dict[usr][i])\n",
    "\n",
    "#             X_data.append(temp)\n",
    "#             usr_data.append(usr)\n",
    "#             try:\n",
    "#                 y_data.append(input_dict[usr][-1])\n",
    "#             except:\n",
    "#                 print(usr)\n",
    "#         else:\n",
    "#             for i in range(size - (window + 1)):\n",
    "#                 temp=[]\n",
    "#                 for j in range(window+1):\n",
    "#                     if j == window:\n",
    "#                         y_data.append(input_dict[usr][i+j])\n",
    "#                     else: \n",
    "#                         temp.append(input_dict[usr][i+j])\n",
    "#                 X_data.append(temp)\n",
    "#                 usr_data.append(usr)\n",
    "\n",
    "# temp = {}\n",
    "# count = 0\n",
    "# for i in set(X_data.reshape(16*4)):\n",
    "#     temp[i] = count\n",
    "#     count+=1\n",
    "\n",
    "# for i in range(len(y_data)):\n",
    "#     if y_data[i] not in temp:\n",
    "#         temp[y_data[i]] = count\n",
    "#         count+=1\n",
    "    \n",
    "# for row in range(len(X_data)):\n",
    "#     for col in range(len(X_data[row])):\n",
    "#         X_data[row][col] = temp[X_data[row][col]]\n",
    "        \n",
    "# for i in range(len(y_data)):\n",
    "#     if y_data[i] in temp:\n",
    "#         y_data[i] = temp[y_data[i]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.add(Bidirectional(LSTM(128), input_shape=(SEQUENCE_LEN, len(words))))\n",
    "# if dropout > 0:\n",
    "#     model.add(Dropout(dropout))\n",
    "# model.add(Dense(len(words)))\n",
    "# model.add(Activation('softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# result = model.evaluate(x_test_pad, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Accuracy: {0:.2%}\".format(result[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=num_loc_time-1,\n",
    "                    output_dim=embedding_size,\n",
    "                    input_length=window,\n",
    "                    name='layer_embedding'))\n",
    "\n",
    "model.add(GRU(4))  # return a single vector of dimension 32\n",
    "model.add(Dense(422, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=Adam(lr=0.01),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# # Generate dummy training data\n",
    "# x_train = np.random.random((1000, timesteps, data_dim))\n",
    "# y_train = np.random.random((1000, num_classes))\n",
    "\n",
    "# Generate dummy validation data\n",
    "# x_val = np.random.random((100, timesteps, data_dim))\n",
    "# y_val = np.random.random((100, num_classes))\n",
    "\n",
    "# model.fit(X_data, y_data, epochs=2, batch_size=64, verbose=2)\n",
    "\n",
    "# model.fit(x_train, y_train,\n",
    "#           batch_size=64, epochs=5,\n",
    "#           validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.summary()\n",
    "# input_data = 0\n",
    "# user_dict = 0\n",
    "# df = 0\n",
    "# df1 = 0\n",
    "y_data = to_categorical(y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/huynh/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:112: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 962 samples, validate on 107 samples\n",
      "Epoch 1/2000\n",
      "962/962 [==============================] - 6s 6ms/step - loss: 5.2314 - acc: 0.0748 - val_loss: 3.9819 - val_acc: 0.0561\n",
      "Epoch 2/2000\n",
      "962/962 [==============================] - 1s 1ms/step - loss: 3.6949 - acc: 0.1975 - val_loss: 3.1446 - val_acc: 0.2897\n",
      "Epoch 3/2000\n",
      "962/962 [==============================] - 1s 961us/step - loss: 3.3145 - acc: 0.2401 - val_loss: 3.0012 - val_acc: 0.2897\n",
      "Epoch 4/2000\n",
      "962/962 [==============================] - 1s 954us/step - loss: 3.2513 - acc: 0.2412 - val_loss: 2.9602 - val_acc: 0.2897\n",
      "Epoch 5/2000\n",
      "962/962 [==============================] - 1s 1ms/step - loss: 3.2258 - acc: 0.2422 - val_loss: 2.9512 - val_acc: 0.2897\n",
      "Epoch 6/2000\n",
      "962/962 [==============================] - 1s 1ms/step - loss: 3.2041 - acc: 0.2412 - val_loss: 2.9297 - val_acc: 0.2897\n",
      "Epoch 7/2000\n",
      "962/962 [==============================] - 1s 1ms/step - loss: 3.1860 - acc: 0.2412 - val_loss: 2.9124 - val_acc: 0.2897\n",
      "Epoch 8/2000\n",
      "962/962 [==============================] - 1s 974us/step - loss: 3.1587 - acc: 0.2422 - val_loss: 2.9015 - val_acc: 0.2897\n",
      "Epoch 9/2000\n",
      "962/962 [==============================] - 1s 974us/step - loss: 3.1386 - acc: 0.2422 - val_loss: 2.8988 - val_acc: 0.2897\n",
      "Epoch 10/2000\n",
      "962/962 [==============================] - 1s 980us/step - loss: 3.1235 - acc: 0.2443 - val_loss: 2.9025 - val_acc: 0.2897\n",
      "Epoch 11/2000\n",
      "962/962 [==============================] - 1s 1ms/step - loss: 3.1127 - acc: 0.2443 - val_loss: 2.8980 - val_acc: 0.2897\n",
      "Epoch 12/2000\n",
      "962/962 [==============================] - 1s 1ms/step - loss: 3.0906 - acc: 0.2453 - val_loss: 2.9062 - val_acc: 0.2897\n",
      "Epoch 13/2000\n",
      "962/962 [==============================] - 1s 1ms/step - loss: 3.0823 - acc: 0.2453 - val_loss: 2.9031 - val_acc: 0.2897\n",
      "Epoch 14/2000\n",
      "962/962 [==============================] - 1s 1ms/step - loss: 3.0662 - acc: 0.2464 - val_loss: 2.8877 - val_acc: 0.2897\n",
      "Epoch 15/2000\n",
      "962/962 [==============================] - 1s 1ms/step - loss: 3.0538 - acc: 0.2484 - val_loss: 2.8856 - val_acc: 0.2897\n",
      "Epoch 16/2000\n",
      "962/962 [==============================] - 1s 1ms/step - loss: 3.0476 - acc: 0.2505 - val_loss: 2.8975 - val_acc: 0.2897\n",
      "Epoch 17/2000\n",
      "962/962 [==============================] - 1s 1ms/step - loss: 3.0345 - acc: 0.2484 - val_loss: 2.9122 - val_acc: 0.2897\n",
      "Epoch 18/2000\n",
      "962/962 [==============================] - 1s 1ms/step - loss: 3.0210 - acc: 0.2484 - val_loss: 2.8837 - val_acc: 0.2897\n",
      "Epoch 19/2000\n",
      "962/962 [==============================] - 1s 1ms/step - loss: 3.0103 - acc: 0.2505 - val_loss: 2.9398 - val_acc: 0.2897\n",
      "Epoch 20/2000\n",
      "962/962 [==============================] - 1s 1ms/step - loss: 3.0009 - acc: 0.2505 - val_loss: 2.9545 - val_acc: 0.2897\n",
      "Epoch 21/2000\n",
      "962/962 [==============================] - 1s 1ms/step - loss: 2.9896 - acc: 0.2505 - val_loss: 2.9730 - val_acc: 0.2710\n",
      "Epoch 22/2000\n",
      "962/962 [==============================] - 1s 1ms/step - loss: 2.9852 - acc: 0.2453 - val_loss: 2.9335 - val_acc: 0.2897\n",
      "Epoch 23/2000\n",
      "962/962 [==============================] - 1s 1ms/step - loss: 2.9516 - acc: 0.2526 - val_loss: 2.9564 - val_acc: 0.2897\n",
      "Epoch 24/2000\n",
      "962/962 [==============================] - 1s 1ms/step - loss: 2.9449 - acc: 0.2484 - val_loss: 2.9239 - val_acc: 0.2897\n",
      "Epoch 25/2000\n",
      "962/962 [==============================] - 1s 1ms/step - loss: 2.9551 - acc: 0.2505 - val_loss: 2.9195 - val_acc: 0.2897\n",
      "Epoch 26/2000\n",
      "962/962 [==============================] - 1s 1ms/step - loss: 2.9465 - acc: 0.2495 - val_loss: 2.9614 - val_acc: 0.2897\n",
      "Epoch 27/2000\n",
      "962/962 [==============================] - 1s 1ms/step - loss: 2.9379 - acc: 0.2484 - val_loss: 2.9526 - val_acc: 0.2897\n",
      "Epoch 28/2000\n",
      "962/962 [==============================] - 1s 1ms/step - loss: 2.9236 - acc: 0.2526 - val_loss: 2.9509 - val_acc: 0.2897\n",
      "Epoch 29/2000\n",
      "962/962 [==============================] - 1s 1ms/step - loss: 2.9190 - acc: 0.2516 - val_loss: 2.9986 - val_acc: 0.2897\n",
      "Epoch 30/2000\n",
      "962/962 [==============================] - 1s 1ms/step - loss: 2.9091 - acc: 0.2516 - val_loss: 2.9745 - val_acc: 0.2897\n",
      "Epoch 31/2000\n",
      "962/962 [==============================] - 1s 1ms/step - loss: 2.9062 - acc: 0.2505 - val_loss: 2.9694 - val_acc: 0.2897\n",
      "Epoch 32/2000\n",
      "962/962 [==============================] - 1s 1ms/step - loss: 2.8962 - acc: 0.2526 - val_loss: 2.9774 - val_acc: 0.2897\n",
      "Epoch 33/2000\n",
      "962/962 [==============================] - 1s 1ms/step - loss: 2.8794 - acc: 0.2526 - val_loss: 2.9813 - val_acc: 0.2897\n",
      "Epoch 34/2000\n",
      "962/962 [==============================] - 1s 1ms/step - loss: 2.8685 - acc: 0.2505 - val_loss: 2.9808 - val_acc: 0.2897\n",
      "Epoch 35/2000\n",
      "962/962 [==============================] - 1s 1ms/step - loss: 2.8729 - acc: 0.2516 - val_loss: 2.9978 - val_acc: 0.2897\n",
      "Epoch 36/2000\n",
      "962/962 [==============================] - 1s 1ms/step - loss: 2.8648 - acc: 0.2474 - val_loss: 2.9970 - val_acc: 0.2897\n",
      "Epoch 37/2000\n",
      "962/962 [==============================] - 1s 1ms/step - loss: 2.8508 - acc: 0.2505 - val_loss: 3.0407 - val_acc: 0.2430\n",
      "Epoch 38/2000\n",
      "962/962 [==============================] - 1s 1ms/step - loss: 2.8527 - acc: 0.2547 - val_loss: 2.9921 - val_acc: 0.2804\n",
      "Epoch 39/2000\n",
      "962/962 [==============================] - 1s 1ms/step - loss: 2.8330 - acc: 0.2547 - val_loss: 2.9766 - val_acc: 0.2523\n",
      "Epoch 40/2000\n",
      "962/962 [==============================] - 1s 1ms/step - loss: 2.8288 - acc: 0.2484 - val_loss: 2.9145 - val_acc: 0.2710\n",
      "Epoch 41/2000\n",
      "962/962 [==============================] - 1s 1ms/step - loss: 2.8295 - acc: 0.2484 - val_loss: 2.9626 - val_acc: 0.2710\n",
      "Epoch 42/2000\n",
      "962/962 [==============================] - 1s 1ms/step - loss: 2.8135 - acc: 0.2620 - val_loss: 3.0203 - val_acc: 0.2523\n",
      "Epoch 43/2000\n",
      "962/962 [==============================] - 1s 1ms/step - loss: 2.8039 - acc: 0.2557 - val_loss: 2.9982 - val_acc: 0.2617\n",
      "Epoch 44/2000\n",
      "962/962 [==============================] - 1s 1ms/step - loss: 2.7984 - acc: 0.2620 - val_loss: 2.9661 - val_acc: 0.2804\n",
      "Epoch 45/2000\n",
      "962/962 [==============================] - 1s 1ms/step - loss: 2.7944 - acc: 0.2651 - val_loss: 2.9615 - val_acc: 0.2710\n",
      "Epoch 46/2000\n",
      "962/962 [==============================] - 1s 1ms/step - loss: 2.7793 - acc: 0.2734 - val_loss: 2.9593 - val_acc: 0.2523\n",
      "Epoch 47/2000\n",
      "962/962 [==============================] - 1s 1ms/step - loss: 2.7732 - acc: 0.2620 - val_loss: 3.0179 - val_acc: 0.2523\n",
      "Epoch 48/2000\n",
      "962/962 [==============================] - 1s 1ms/step - loss: 2.7594 - acc: 0.2744 - val_loss: 3.0015 - val_acc: 0.2617\n",
      "Epoch 49/2000\n",
      "962/962 [==============================] - 1s 1ms/step - loss: 2.7591 - acc: 0.2734 - val_loss: 2.9892 - val_acc: 0.2804\n",
      "Epoch 50/2000\n",
      "962/962 [==============================] - 1s 1ms/step - loss: 2.7424 - acc: 0.2723 - val_loss: 2.9704 - val_acc: 0.2710\n",
      "Epoch 51/2000\n",
      "962/962 [==============================] - 1s 1ms/step - loss: 2.7419 - acc: 0.2859 - val_loss: 2.9759 - val_acc: 0.2710\n",
      "Epoch 52/2000\n",
      "962/962 [==============================] - 1s 1ms/step - loss: 2.7376 - acc: 0.2911 - val_loss: 2.9672 - val_acc: 0.2710\n",
      "Epoch 53/2000\n",
      "962/962 [==============================] - 1s 1ms/step - loss: 2.7449 - acc: 0.2921 - val_loss: 2.9748 - val_acc: 0.2804\n",
      "Epoch 54/2000\n",
      "962/962 [==============================] - 1s 1ms/step - loss: 2.7310 - acc: 0.2838 - val_loss: 2.9745 - val_acc: 0.2804\n",
      "Epoch 55/2000\n",
      "962/962 [==============================] - 1s 1ms/step - loss: 2.7420 - acc: 0.2900 - val_loss: 2.9776 - val_acc: 0.2710\n",
      "Epoch 56/2000\n",
      "962/962 [==============================] - 1s 1ms/step - loss: 2.7129 - acc: 0.2963 - val_loss: 2.9866 - val_acc: 0.2710\n",
      "Epoch 57/2000\n",
      "962/962 [==============================] - 1s 1ms/step - loss: 2.7160 - acc: 0.2942 - val_loss: 2.9685 - val_acc: 0.2710\n",
      "Epoch 58/2000\n",
      "962/962 [==============================] - 1s 1ms/step - loss: 2.6994 - acc: 0.3025 - val_loss: 2.9645 - val_acc: 0.2710\n",
      "Epoch 59/2000\n",
      "962/962 [==============================] - 1s 1ms/step - loss: 2.6936 - acc: 0.3098 - val_loss: 2.9679 - val_acc: 0.3084\n",
      "Epoch 60/2000\n",
      "962/962 [==============================] - 1s 1ms/step - loss: 2.6868 - acc: 0.3046 - val_loss: 2.9712 - val_acc: 0.2804\n",
      "Epoch 61/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "962/962 [==============================] - 1s 1ms/step - loss: 2.6823 - acc: 0.3015 - val_loss: 2.9663 - val_acc: 0.2710\n",
      "Epoch 62/2000\n",
      "962/962 [==============================] - 1s 1ms/step - loss: 2.6733 - acc: 0.3077 - val_loss: 2.9598 - val_acc: 0.3084\n",
      "Epoch 63/2000\n",
      "962/962 [==============================] - 1s 1ms/step - loss: 2.6721 - acc: 0.2952 - val_loss: 2.9619 - val_acc: 0.2710\n",
      "Epoch 64/2000\n",
      "962/962 [==============================] - 1s 1ms/step - loss: 2.6766 - acc: 0.3098 - val_loss: 2.9614 - val_acc: 0.2710\n",
      "Epoch 65/2000\n",
      "962/962 [==============================] - 1s 1ms/step - loss: 2.6655 - acc: 0.3087 - val_loss: 2.9522 - val_acc: 0.2804\n",
      "Epoch 66/2000\n",
      "962/962 [==============================] - 1s 1ms/step - loss: 2.6613 - acc: 0.3077 - val_loss: 2.9250 - val_acc: 0.3271\n",
      "Epoch 67/2000\n",
      "962/962 [==============================] - 1s 1ms/step - loss: 2.6569 - acc: 0.3067 - val_loss: 2.9546 - val_acc: 0.2897\n",
      "Epoch 68/2000\n",
      "962/962 [==============================] - 1s 1ms/step - loss: 2.6524 - acc: 0.3108 - val_loss: 2.9421 - val_acc: 0.2804\n",
      "Epoch 69/2000\n",
      "962/962 [==============================] - 1s 1ms/step - loss: 2.6501 - acc: 0.3056 - val_loss: 2.9555 - val_acc: 0.2710\n",
      "Epoch 70/2000\n",
      "962/962 [==============================] - 1s 1ms/step - loss: 2.6395 - acc: 0.3139 - val_loss: 2.9586 - val_acc: 0.2804\n",
      "Epoch 71/2000\n",
      "962/962 [==============================] - 1s 1ms/step - loss: 2.6363 - acc: 0.3150 - val_loss: 2.9412 - val_acc: 0.2710\n",
      "Epoch 72/2000\n",
      "962/962 [==============================] - 1s 1ms/step - loss: 2.6430 - acc: 0.3108 - val_loss: 2.9595 - val_acc: 0.3084\n",
      "Epoch 73/2000\n",
      "962/962 [==============================] - 1s 1ms/step - loss: 2.6523 - acc: 0.3046 - val_loss: 2.9611 - val_acc: 0.2710\n",
      "Epoch 74/2000\n",
      "962/962 [==============================] - 1s 1ms/step - loss: 2.6410 - acc: 0.3046 - val_loss: 2.9437 - val_acc: 0.2710\n",
      "Epoch 75/2000\n",
      "962/962 [==============================] - 1s 1ms/step - loss: 2.6226 - acc: 0.3139 - val_loss: 2.9285 - val_acc: 0.2804\n",
      "Epoch 76/2000\n",
      "962/962 [==============================] - 1s 1ms/step - loss: 2.6276 - acc: 0.3119 - val_loss: 2.9433 - val_acc: 0.3084\n",
      "Epoch 77/2000\n",
      "962/962 [==============================] - 1s 1ms/step - loss: 2.6213 - acc: 0.3150 - val_loss: 2.9428 - val_acc: 0.2991\n",
      "Epoch 78/2000\n",
      "962/962 [==============================] - 1s 1ms/step - loss: 2.6077 - acc: 0.3108 - val_loss: 2.9714 - val_acc: 0.2804\n",
      "Epoch 79/2000\n",
      "962/962 [==============================] - 1s 1ms/step - loss: 2.6092 - acc: 0.3150 - val_loss: 2.9682 - val_acc: 0.2804\n",
      "Epoch 80/2000\n",
      "962/962 [==============================] - 1s 1ms/step - loss: 2.6058 - acc: 0.3160 - val_loss: 2.9527 - val_acc: 0.3178\n",
      "Epoch 81/2000\n",
      "962/962 [==============================] - 1s 1ms/step - loss: 2.5972 - acc: 0.3150 - val_loss: 2.9642 - val_acc: 0.3364\n",
      "Epoch 82/2000\n",
      "962/962 [==============================] - 1s 996us/step - loss: 2.6020 - acc: 0.3150 - val_loss: 2.9420 - val_acc: 0.3084\n",
      "Epoch 83/2000\n",
      "962/962 [==============================] - 1s 992us/step - loss: 2.6059 - acc: 0.3119 - val_loss: 2.9474 - val_acc: 0.3178\n",
      "Epoch 84/2000\n",
      "962/962 [==============================] - 1s 1ms/step - loss: 2.5997 - acc: 0.3077 - val_loss: 2.9768 - val_acc: 0.2804\n",
      "Epoch 85/2000\n",
      "962/962 [==============================] - 1s 1ms/step - loss: 2.5952 - acc: 0.3222 - val_loss: 2.9602 - val_acc: 0.3178\n",
      "Epoch 86/2000\n",
      "962/962 [==============================] - 1s 975us/step - loss: 2.5945 - acc: 0.3129 - val_loss: 2.9428 - val_acc: 0.3084\n",
      "Epoch 87/2000\n",
      "962/962 [==============================] - 1s 1ms/step - loss: 2.5888 - acc: 0.3181 - val_loss: 2.9511 - val_acc: 0.2804\n",
      "Epoch 88/2000\n",
      "962/962 [==============================] - 1s 1ms/step - loss: 2.5932 - acc: 0.3129 - val_loss: 2.9470 - val_acc: 0.3178\n",
      "Epoch 89/2000\n",
      "962/962 [==============================] - 1s 1ms/step - loss: 2.5822 - acc: 0.3150 - val_loss: 2.9448 - val_acc: 0.3178\n",
      "Epoch 90/2000\n",
      "962/962 [==============================] - 1s 1ms/step - loss: 2.5918 - acc: 0.3129 - val_loss: 2.9687 - val_acc: 0.2804\n",
      "Epoch 91/2000\n",
      "962/962 [==============================] - 1s 1ms/step - loss: 2.5864 - acc: 0.3077 - val_loss: 2.9641 - val_acc: 0.2804\n",
      "Epoch 92/2000\n",
      "962/962 [==============================] - 1s 1ms/step - loss: 2.5799 - acc: 0.3181 - val_loss: 2.9625 - val_acc: 0.2710\n",
      "Epoch 93/2000\n",
      "962/962 [==============================] - 1s 1ms/step - loss: 2.5778 - acc: 0.3170 - val_loss: 2.9662 - val_acc: 0.2897\n",
      "Epoch 94/2000\n",
      "962/962 [==============================] - 1s 1ms/step - loss: 2.5710 - acc: 0.3170 - val_loss: 2.9700 - val_acc: 0.3178\n",
      "Epoch 95/2000\n",
      "962/962 [==============================] - 1s 1ms/step - loss: 2.5761 - acc: 0.3087 - val_loss: 2.9650 - val_acc: 0.3084\n",
      "Epoch 96/2000\n",
      "962/962 [==============================] - 1s 1ms/step - loss: 2.5687 - acc: 0.3212 - val_loss: 2.9752 - val_acc: 0.3178\n",
      "Epoch 97/2000\n",
      "962/962 [==============================] - 1s 1ms/step - loss: 2.5737 - acc: 0.3108 - val_loss: 2.9308 - val_acc: 0.3178\n",
      "Epoch 98/2000\n",
      "962/962 [==============================] - 1s 1ms/step - loss: 2.5686 - acc: 0.3119 - val_loss: 2.9515 - val_acc: 0.3178\n",
      "Epoch 99/2000\n",
      "962/962 [==============================] - 1s 1ms/step - loss: 2.5612 - acc: 0.3191 - val_loss: 2.9541 - val_acc: 0.3084\n",
      "Epoch 100/2000\n",
      "962/962 [==============================] - 1s 1ms/step - loss: 2.5633 - acc: 0.3160 - val_loss: 2.9779 - val_acc: 0.2991\n",
      "Epoch 101/2000\n",
      "962/962 [==============================] - 1s 1ms/step - loss: 2.5653 - acc: 0.3119 - val_loss: 2.9691 - val_acc: 0.3084\n",
      "Epoch 102/2000\n",
      "962/962 [==============================] - 1s 1ms/step - loss: 2.5628 - acc: 0.3212 - val_loss: 2.9753 - val_acc: 0.3084\n",
      "Epoch 103/2000\n",
      "962/962 [==============================] - 1s 1ms/step - loss: 2.5544 - acc: 0.3274 - val_loss: 3.0069 - val_acc: 0.2897\n",
      "Epoch 104/2000\n",
      "962/962 [==============================] - 1s 1ms/step - loss: 2.5521 - acc: 0.3170 - val_loss: 3.0064 - val_acc: 0.2804\n",
      "Epoch 105/2000\n",
      "962/962 [==============================] - 1s 1ms/step - loss: 2.5489 - acc: 0.3181 - val_loss: 3.0139 - val_acc: 0.3084\n",
      "Epoch 106/2000\n",
      "962/962 [==============================] - 1s 1ms/step - loss: 2.5610 - acc: 0.3098 - val_loss: 3.0385 - val_acc: 0.2991\n",
      "Epoch 107/2000\n",
      "962/962 [==============================] - 1s 1ms/step - loss: 2.5702 - acc: 0.3170 - val_loss: 3.0153 - val_acc: 0.2710\n",
      "Epoch 108/2000\n",
      "962/962 [==============================] - 1s 1ms/step - loss: 2.5555 - acc: 0.3160 - val_loss: 3.0251 - val_acc: 0.3178\n",
      "Epoch 109/2000\n",
      "962/962 [==============================] - 1s 1ms/step - loss: 2.5537 - acc: 0.3160 - val_loss: 2.9934 - val_acc: 0.3084\n",
      "Epoch 110/2000\n",
      "962/962 [==============================] - 1s 1ms/step - loss: 2.5544 - acc: 0.3170 - val_loss: 3.0136 - val_acc: 0.2991\n",
      "Epoch 111/2000\n",
      "962/962 [==============================] - 1s 1ms/step - loss: 2.5401 - acc: 0.3170 - val_loss: 3.0169 - val_acc: 0.3084\n",
      "Epoch 112/2000\n",
      "962/962 [==============================] - 1s 1ms/step - loss: 2.5459 - acc: 0.3233 - val_loss: 3.0234 - val_acc: 0.2897\n",
      "Epoch 113/2000\n",
      "962/962 [==============================] - 1s 1ms/step - loss: 2.5509 - acc: 0.3170 - val_loss: 3.0369 - val_acc: 0.2991\n",
      "Epoch 114/2000\n",
      "962/962 [==============================] - 1s 1ms/step - loss: 2.5721 - acc: 0.3150 - val_loss: 3.0473 - val_acc: 0.2804\n",
      "Epoch 115/2000\n",
      "962/962 [==============================] - 1s 1ms/step - loss: 2.5686 - acc: 0.3129 - val_loss: 3.0365 - val_acc: 0.2991\n",
      "Epoch 116/2000\n",
      "962/962 [==============================] - 1s 1ms/step - loss: 2.5516 - acc: 0.3087 - val_loss: 3.0260 - val_acc: 0.2804\n",
      "Epoch 117/2000\n",
      "962/962 [==============================] - 1s 1ms/step - loss: 2.5516 - acc: 0.3212 - val_loss: 3.0461 - val_acc: 0.2710\n",
      "Epoch 118/2000\n",
      "962/962 [==============================] - 1s 1ms/step - loss: 2.5501 - acc: 0.3129 - val_loss: 3.0306 - val_acc: 0.2523\n",
      "Epoch 119/2000\n",
      "962/962 [==============================] - 1s 1ms/step - loss: 2.5448 - acc: 0.3119 - val_loss: 3.0322 - val_acc: 0.2804\n",
      "Epoch 120/2000\n",
      "962/962 [==============================] - 1s 1ms/step - loss: 2.5411 - acc: 0.3119 - val_loss: 3.0509 - val_acc: 0.2617\n",
      "Epoch 121/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "962/962 [==============================] - 1s 1ms/step - loss: 2.5444 - acc: 0.3139 - val_loss: 3.0461 - val_acc: 0.2991\n",
      "Epoch 122/2000\n",
      "962/962 [==============================] - 1s 1ms/step - loss: 2.5266 - acc: 0.3129 - val_loss: 3.0443 - val_acc: 0.2804\n",
      "Epoch 123/2000\n",
      "962/962 [==============================] - 1s 1ms/step - loss: 2.5310 - acc: 0.3160 - val_loss: 3.0483 - val_acc: 0.2991\n",
      "Epoch 124/2000\n",
      "962/962 [==============================] - 1s 1ms/step - loss: 2.5190 - acc: 0.3191 - val_loss: 3.0527 - val_acc: 0.3084\n",
      "Epoch 125/2000\n",
      "962/962 [==============================] - 1s 1ms/step - loss: 2.5184 - acc: 0.3222 - val_loss: 3.0465 - val_acc: 0.3084\n",
      "Epoch 126/2000\n",
      "962/962 [==============================] - 1s 1ms/step - loss: 2.5283 - acc: 0.3222 - val_loss: 3.0478 - val_acc: 0.3084\n",
      "Epoch 127/2000\n",
      "962/962 [==============================] - 1s 1ms/step - loss: 2.5251 - acc: 0.3191 - val_loss: 3.0563 - val_acc: 0.2991\n",
      "Epoch 128/2000\n",
      "962/962 [==============================] - 1s 1ms/step - loss: 2.5284 - acc: 0.3212 - val_loss: 3.0524 - val_acc: 0.2991\n",
      "Epoch 129/2000\n",
      "962/962 [==============================] - 1s 1ms/step - loss: 2.5208 - acc: 0.3139 - val_loss: 3.0534 - val_acc: 0.3084\n",
      "Epoch 130/2000\n",
      "962/962 [==============================] - 1s 1ms/step - loss: 2.5266 - acc: 0.3243 - val_loss: 3.0496 - val_acc: 0.2991\n",
      "Epoch 131/2000\n",
      "962/962 [==============================] - 1s 1ms/step - loss: 2.5406 - acc: 0.3170 - val_loss: 3.1060 - val_acc: 0.2710\n",
      "Epoch 132/2000\n",
      "962/962 [==============================] - 1s 1ms/step - loss: 2.5260 - acc: 0.3170 - val_loss: 3.0979 - val_acc: 0.2710\n",
      "Epoch 133/2000\n",
      "962/962 [==============================] - 1s 1ms/step - loss: 2.5380 - acc: 0.3129 - val_loss: 3.1513 - val_acc: 0.2523\n",
      "Epoch 134/2000\n",
      "962/962 [==============================] - 1s 1ms/step - loss: 2.5445 - acc: 0.3139 - val_loss: 3.1591 - val_acc: 0.2523\n",
      "Epoch 135/2000\n",
      "962/962 [==============================] - 1s 1ms/step - loss: 2.5249 - acc: 0.3222 - val_loss: 3.1170 - val_acc: 0.2710\n",
      "Epoch 136/2000\n",
      "962/962 [==============================] - 1s 1ms/step - loss: 2.5236 - acc: 0.3160 - val_loss: 3.1283 - val_acc: 0.2897\n",
      "Epoch 137/2000\n",
      "962/962 [==============================] - 1s 1ms/step - loss: 2.5185 - acc: 0.3222 - val_loss: 3.1353 - val_acc: 0.2430\n",
      "Epoch 138/2000\n",
      "962/962 [==============================] - 1s 1ms/step - loss: 2.5104 - acc: 0.3181 - val_loss: 3.1348 - val_acc: 0.2710\n",
      "Epoch 139/2000\n",
      "962/962 [==============================] - 1s 1ms/step - loss: 2.5148 - acc: 0.3202 - val_loss: 3.1327 - val_acc: 0.2804\n",
      "Epoch 140/2000\n",
      "962/962 [==============================] - 1s 1ms/step - loss: 2.5122 - acc: 0.3181 - val_loss: 3.1298 - val_acc: 0.2897\n",
      "Epoch 141/2000\n",
      "962/962 [==============================] - 1s 1ms/step - loss: 2.5122 - acc: 0.3191 - val_loss: 3.1360 - val_acc: 0.2617\n",
      "Epoch 142/2000\n",
      "962/962 [==============================] - 1s 1ms/step - loss: 2.5111 - acc: 0.3170 - val_loss: 3.1384 - val_acc: 0.2804\n",
      "Epoch 143/2000\n",
      "962/962 [==============================] - 1s 1ms/step - loss: 2.5142 - acc: 0.3222 - val_loss: 3.1171 - val_acc: 0.2804\n",
      "Epoch 144/2000\n",
      "962/962 [==============================] - 1s 1ms/step - loss: 2.5044 - acc: 0.3139 - val_loss: 3.1106 - val_acc: 0.2804\n",
      "Epoch 145/2000\n",
      "962/962 [==============================] - 1s 1ms/step - loss: 2.4978 - acc: 0.3181 - val_loss: 3.1467 - val_acc: 0.2523\n",
      "Epoch 146/2000\n",
      "962/962 [==============================] - 1s 1ms/step - loss: 2.5009 - acc: 0.3274 - val_loss: 3.1663 - val_acc: 0.2617\n",
      "Epoch 147/2000\n",
      "672/962 [===================>..........] - ETA: 0s - loss: 2.5431 - acc: 0.3095"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-130-2b8bdf08a8af>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1637\u001b[0m           \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1638\u001b[0m           \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1639\u001b[0;31m           validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1640\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1641\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    213\u001b[0m           \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 215\u001b[0;31m         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    216\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m           \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2984\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2985\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 2986\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   2987\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2988\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(X_data, y_data, validation_split=0.1, epochs=2000, batch_size=32, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "modela = Sequential()\n",
    "modela.add(Embedding(input_dim=num_loc_time,\n",
    "                    output_dim=embedding_size,\n",
    "                    input_length=window,\n",
    "                    name='layer_embedding'))\n",
    "\n",
    "# model.add(Bidirectional(LSTM(128, return_sequences=True)))\n",
    "# model.add(Bidirectional(LSTM(64, return_sequences=True)))\n",
    "modela.add(Bidirectional(LSTM(32)))\n",
    "\n",
    "# modela.add(Dense(500, activation='relu'))\n",
    "modela.add(Dense(100, activation='relu'))\n",
    "\n",
    "\n",
    "modelb = Sequential()\n",
    "modelb.add(Embedding(input_dim=a,\n",
    "                    output_dim=20,\n",
    "                    input_length=1,\n",
    "                    name='layer_embedding1'))\n",
    "\n",
    "modelb.add(Dense(20, activation='relu'))\n",
    "modelb.add(Flatten())\n",
    "\n",
    "modelc = Sequential()\n",
    "modelc.add(Dense(5, activation='relu', input_shape=(7,)))\n",
    "modelc.add(Flatten())\n",
    "\n",
    "\n",
    "merged_output = concatenate([modela.output, modelb.output, modelc.output])\n",
    "model_combined = Sequential()\n",
    "\n",
    "model_combined.add(Dense(num_loc_time, activation='softmax'))\n",
    "\n",
    "final_model = Model([modela.input, modelb.input, modelc.input], model_combined(merged_output))\n",
    "final_model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=Adam(lr=0.001),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_data1 = to_categorical(y_data)\n",
    "week_data1 = to_categorical(week_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/huynh/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:112: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3106032 samples, validate on 345115 samples\n",
      "Epoch 1/200\n",
      "   7200/3106032 [..............................] - ETA: 3:53:14 - loss: 7.6111 - acc: 0.0126"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-169-94b96071591d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfinal_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0musr_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweek_data1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_data1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1637\u001b[0m           \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1638\u001b[0m           \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1639\u001b[0;31m           validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1640\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1641\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    213\u001b[0m           \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 215\u001b[0;31m         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    216\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m           \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2984\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2985\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 2986\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   2987\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2988\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "final_model.fit([X_data, usr_data, week_data1], y_data1, validation_split=0.1, epochs=200, batch_size=32, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3463942, 64221)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_data1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4036\n",
      "4\n",
      "4\n",
      "240\n",
      "(168473, 4036)\n"
     ]
    }
   ],
   "source": [
    "print(num_loc_time)\n",
    "print(embedding_size)\n",
    "print(window)\n",
    "print(a)\n",
    "print(y_data1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "input1 = Input(shape=(16,))\n",
    "x1 = Dense(8, activation='relu')(input1)\n",
    "input2 = Input(shape=(32,))\n",
    "x2 = Dense(8, activation='relu')(input2)\n",
    "added = add([x1, x2])\n",
    "\n",
    "\n",
    "out = Dense(4)(added)\n",
    "model = Model(inputs=[input1, input2], outputs=out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_5 (InputLayer)            (None, 16)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_6 (InputLayer)            (None, 32)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_35 (Dense)                (None, 8)            136         input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_36 (Dense)                (None, 8)            264         input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 8)            0           dense_35[0][0]                   \n",
      "                                                                 dense_36[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_37 (Dense)                (None, 4)            36          add_10[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 436\n",
      "Trainable params: 436\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'Client Username', 'Client IP Address',\n",
       "       'Client MAC Address', 'Association Time', 'Vendor', 'AP Name',\n",
       "       'Radio Type', 'Device Name', 'Map Location', 'SSID', 'Profile',\n",
       "       'VLAN ID', 'Protocol', 'Session Duration', 'Policy Type',\n",
       "       'Avg. Session Throughput(Kbps)'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../all_data.csv')\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3156"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(df['AP Name'].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
