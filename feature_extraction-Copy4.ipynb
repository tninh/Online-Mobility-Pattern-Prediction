{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from hmmlearn import hmm\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import datetime\n",
    "# import pykovy-master/ \n",
    "from pykovy.src.pykovy import chain\n",
    "import matplotlib.pyplot as plt\n",
    "from time import time\n",
    "import networkx as nx\n",
    "import math\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# from tf.keras.models import Sequential  # This does not work!\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Dense, GRU, Embedding, LSTM\n",
    "from tensorflow.python.keras.optimizers import Adam\n",
    "# from tensorflow.python.keras.preprocessing.text import Tokenizer\n",
    "# from tensorflow.python.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.python.keras.utils import to_categorical\n",
    "\n",
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# np.random.seed(42)\n",
    "\n",
    "# model = hmm.GaussianHMM(n_components=3, covariance_type=\"full\")\n",
    "# model.startprob_ = np.array([0.6, 0.3, 0.1])\n",
    "# model.transmat_ = np.array([[0.7, 0.2, 0.1],\n",
    "#                             [0.3, 0.5, 0.2],\n",
    "#                             [0.3, 0.3, 0.4]])\n",
    "# model.means_ = np.array([[0.0, 0.0], [3.0, -3.0], [5.0, 10.0]])\n",
    "# model.covars_ = np.tile(np.identity(2), (3, 1, 1))\n",
    "# X, Z = model.sample(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv('../all_data.csv')\n",
    "# df = df[['Client Username', 'Association Time', 'Map Location', 'Session Duration']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# re-code userid\n",
    "# df['Client Username'] = pd.Categorical(df['Client Username'])\n",
    "# df['Client Username'] = df['Client Username'].cat.codes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../all_data.csv')\n",
    "df = df[['Client Username', 'Association Time', 'Map Location', 'Session Duration', 'Client MAC Address']]\n",
    "df = df.assign(id=(df['Client Username'] + '_' + df['Client MAC Address']).astype('category').cat.codes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['Client Username', 'Client MAC Address'], axis=1)\n",
    "df.rename(columns={'id':'Client Username'}, inplace=True)\n",
    "df = df[['Client Username', 'Association Time', 'Map Location', 'Session Duration']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# recode map location\n",
    "map_dict = {}\n",
    "count = 0\n",
    "for i in df['Map Location'].unique():\n",
    "    map_dict[i] = count\n",
    "    count += 1\n",
    "df['Map Location'] = df['Map Location'].map(map_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# df[df['Map Location']==64]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def timer(func):\n",
    "    # this part is for timer ignore\n",
    "    def wrapper(*arg):\n",
    "        before = time()\n",
    "        rv = func(*arg)\n",
    "        after = time()\n",
    "        print('Elapsed: ', after-before)\n",
    "        return rv\n",
    "    return wrapper\n",
    "\n",
    "def convertMonth(month):\n",
    "    if month == 'Jan': return 1\n",
    "    elif month == 'Feb': return 2\n",
    "    elif month == 'Mar': return 3\n",
    "    elif month == 'Apr': return 4\n",
    "    elif month == 'May': return 5\n",
    "    elif month == 'Jun': return 6\n",
    "    elif month == 'Jul': return 7\n",
    "    elif month == 'Aug': return 8\n",
    "    elif month == 'Sep': return 9\n",
    "    elif month == 'Oct': return 10\n",
    "    elif month == 'Nov': return 11\n",
    "    elif month == 'Dec': return 12\n",
    "    else: print('error input is not correct')\n",
    "        \n",
    "def convert_to_timeslot(duration):\n",
    "    temp = duration.split()\n",
    "    if len(temp) == 2: sess_duration = int(temp[0])\n",
    "    elif len(temp) == 4: sess_duration = int(temp[0]) * 60 + int(temp[2])\n",
    "    elif len(temp) == 6: sess_duration = (int(temp[0]) * 60 + int(temp[2])) * 60 + int(temp[4])\n",
    "    else: print('error')\n",
    "    return datetime.timedelta(seconds=sess_duration)\n",
    "\n",
    "def convert_to_datetime(time):\n",
    "    temp = time.split()\n",
    "    d_time = datetime.datetime(year=int(temp[5]), month=convertMonth(temp[1]), day=int(temp[2]), hour=int(temp[3].split(':')[0]), minute=int(temp[3].split(':')[1]), second=int(temp[3].split(':')[2]))\n",
    "    return d_time\n",
    "\n",
    "# data_list has same number of row as df.\n",
    "# Each row [userid, map_loc, associate_time, associate_time+sess_dur, sess_dur].\n",
    "def create_data_list(df):\n",
    "    data_list = []\n",
    "    c=0\n",
    "    for i in range(df.shape[0]):\n",
    "        if c%500000 == 0:\n",
    "            print(c)\n",
    "        sess = convert_to_timeslot(df.iloc[i,3])\n",
    "        s_time = convert_to_datetime(df.iloc[i,1])\n",
    "        e_time = s_time + sess\n",
    "        data_list.append([df.iloc[i,0], df.iloc[i,2], s_time, e_time, sess])\n",
    "        c+=1\n",
    "        \n",
    "    data_list = sorted(data_list, key=lambda element: (element[0], element[2]))\n",
    "    data_list1 = sorted(data_list, key=lambda element: (element[2]))\n",
    "    first = data_list1[0][2]\n",
    "    last = data_list1[-1][2]\n",
    "    return data_list, first, last\n",
    "\n",
    "# add up the session duration when the previous row has the same userid and location. \n",
    "# (this happen when you disconnect from the ap and reconnect again or your wifi session expire, etc.)\n",
    "def preprocess_data_list(df, data_list):\n",
    "    for i in reversed(range(1, df.shape[0])):\n",
    "        if data_list[i][0] == data_list[i-1][0] and data_list[i][1] == data_list[i-1][1]:\n",
    "#             if data_list[i][2] - data_list[i-1][3] <= datetime.timedelta(hours=2):\n",
    "            data_list[i-1][4] += data_list[i][4]\n",
    "#             else: print(i)\n",
    "    # loop each row, remove the next concecutive rows has the same userid and map_loc with the current row.\n",
    "    # Because they are useless now\n",
    "    final_data_list = []\n",
    "    i = 0\n",
    "    while i < df.shape[0]-1:\n",
    "        if data_list[i][0] == data_list[i+1][0] and data_list[i][1] == data_list[i+1][1]:\n",
    "            final_data_list.append(data_list[i])\n",
    "            c = 2\n",
    "            while i+c <= df.shape[0]-1 and data_list[i][0] == data_list[i+c][0] and data_list[i][1] == data_list[i+c][1]:\n",
    "                c += 1\n",
    "            i += c\n",
    "\n",
    "        else:\n",
    "            final_data_list.append(data_list[i])\n",
    "            i += 1\n",
    "\n",
    "    if not (final_data_list[-1][0] == data_list[-1][0] and final_data_list[-1][1] == data_list[-1][1]):\n",
    "        final_data_list.append(data_list[-1])\n",
    "\n",
    "    return final_data_list\n",
    "\n",
    "\n",
    "# user_dict's key are each userid and value is a list of all rows of each user in final_data_list\n",
    "def create_user_dict(final_data_list):\n",
    "    user_dict = defaultdict(list)\n",
    "    for row in final_data_list:\n",
    "        user_dict[row[0]].append([row[2], row[1], row[4]])\n",
    "        \n",
    "#     for usr in user_dict:\n",
    "#         user_dict[usr].sort()\n",
    "\n",
    "    return user_dict\n",
    "\n",
    "# \n",
    "def remove_jitter(final_data_list):\n",
    "    res = [final_data_list[0]]\n",
    "    i = 1\n",
    "    mem = 0\n",
    "    while i < len(final_data_list):\n",
    "        cur_usrid = final_data_list[i][0]\n",
    "        cur_loc = final_data_list[i][1]\n",
    "        cur_sess = final_data_list[i][4]\n",
    "        cur_end_time = final_data_list[i][2] + final_data_list[i][4]\n",
    "        cont_time = final_data_list[i][2] - (res[-1][2] + res[-1][4]) <= datetime.timedelta(minutes=1)\n",
    "        if cur_usrid == res[-1][0] and cur_sess <= datetime.timedelta(minutes=1) and cont_time:\n",
    "\n",
    "\n",
    "            if cur_loc != res[-1][1] and mem == 0:\n",
    "                mem = i\n",
    "\n",
    "            elif cur_loc == res[-1][1]:\n",
    "                \n",
    "#                 print(i, cur_loc, cur_end_time, res[-1][1], res[-1][2])\n",
    "\n",
    "#                 print(cur_end_time - res[-1][2])\n",
    "                res[-1][4] = cur_end_time - res[-1][2]\n",
    "#                 print(res[-1][4])\n",
    "                mem=0\n",
    "                \n",
    "            else: pass\n",
    "        elif cur_usrid == res[-1][0] and cur_sess <= datetime.timedelta(minutes=1) and not cont_time:\n",
    "            if cur_loc != res[-1][1] and mem == 0:\n",
    "                res.append(final_data_list[i])\n",
    "\n",
    "            elif cur_loc == res[-1][1]:\n",
    "                res[-1][4] = cur_end_time - res[-1][2]\n",
    "                mem=0\n",
    "                \n",
    "            else:                 \n",
    "                for j in range(mem, i):\n",
    "                    res.append(final_data_list[j])\n",
    "                res.append(final_data_list[i])\n",
    "                mem=0\n",
    "        else:\n",
    "            if mem != 0:\n",
    "                for j in range(mem, i):\n",
    "                    res.append(final_data_list[j])\n",
    "                res.append(final_data_list[i])\n",
    "                mem=0\n",
    "            else: res.append(final_data_list[i])\n",
    "        \n",
    "        i+=1\n",
    "\n",
    "    return res\n",
    "\n",
    "@timer\n",
    "def preprocess_and_create_user_dict(df):\n",
    "    data_list, start_ts, end_ts= create_data_list(df)\n",
    "    final_data_list = preprocess_data_list(df, data_list)\n",
    "    print(len(final_data_list), len(data_list))\n",
    "    final_data_list = remove_jitter(final_data_list)\n",
    "    print(len(final_data_list), len(data_list))\n",
    "    user_dict = create_user_dict(final_data_list)\n",
    "    return user_dict, start_ts, end_ts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "500000\n",
      "1000000\n",
      "1500000\n",
      "2000000\n",
      "2500000\n",
      "3000000\n",
      "3500000\n",
      "4000000\n",
      "4500000\n",
      "5000000\n",
      "5500000\n",
      "6000000\n",
      "2350637 6114987\n",
      "2350635 6114987\n",
      "Elapsed:  394.6935181617737\n"
     ]
    }
   ],
   "source": [
    "user_dict, start_ts, end_ts = preprocess_and_create_user_dict(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [i for i in user_dict if len(user_dict[i]) < 50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# user_dict1 = {}\n",
    "# for i in user_dict:\n",
    "#     if not i in a:\n",
    "#         user_dict1[i] = user_dict[i]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = map(user_dict.pop, a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(a)):\n",
    "    try:\n",
    "        next(t)\n",
    "    except:\n",
    "        print('fail')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11396"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(user_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_timeslot1(d_time):\n",
    "    slot = (d_time.hour * 60 + d_time.minute)/15\n",
    "    return int(slot) if slot < int(slot) + 0.5 else int(slot) + 1\n",
    "\n",
    "def create_data(user_dict):\n",
    "    input_data = []\n",
    "    c = 0\n",
    "    for usr in user_dict:\n",
    "        c+=1\n",
    "        if c % 5000 == 0: print(c)\n",
    "        for j in range(len(user_dict[usr] )-1):\n",
    "            slot = convert_to_timeslot1(user_dict[usr][j][0])\n",
    "            loc = user_dict[usr][j][1]\n",
    "#             input_data.append([usr, str(slot) + '_' + str(loc)])\n",
    "            input_data.append([usr, str(loc)])\n",
    "\n",
    "\n",
    "            \n",
    "    return input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "input_data = create_data(user_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame(data=input_data, columns=['userID', 'arrival_slot and location'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recode map location\n",
    "map_dict_time_loc = {}\n",
    "num_loc_time = 1\n",
    "for i in df1['arrival_slot and location'].unique():\n",
    "    map_dict_time_loc[i] = num_loc_time\n",
    "    num_loc_time += 1\n",
    "df1['arrival_slot and location'] = df1['arrival_slot and location'].map(map_dict_time_loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userID</th>\n",
       "      <th>arrival_slot and location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userID  arrival_slot and location\n",
       "0       6                          1\n",
       "1       6                          2\n",
       "2       6                          1\n",
       "3       6                          3\n",
       "4       6                          1"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "1300000\n",
      "1400000\n",
      "1500000\n"
     ]
    }
   ],
   "source": [
    "input_dict = defaultdict(list)\n",
    "for i in range(df1.shape[0]):\n",
    "    if i % 100000 == 0: print(i)\n",
    "    input_dict[df1.loc[i]['userID']].append(df1.loc[i]['arrival_slot and location'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data = []\n",
    "y_data = []\n",
    "window = 5\n",
    "\n",
    "for usr in input_dict:\n",
    "    size = len(input_dict[usr])\n",
    "    \n",
    "    if size == 0: continue\n",
    "    elif size <= window:\n",
    "        temp = []\n",
    "        for _ in range(window - size):\n",
    "            temp.append(0)\n",
    "        for i in range(size):\n",
    "            temp.append(input_dict[usr][i])\n",
    "        \n",
    "        X_data.append(temp)\n",
    "        try:\n",
    "            y_data.append(input_dict[usr][-1])\n",
    "        except:\n",
    "            print(usr)\n",
    "    else:\n",
    "        for i in range(size - (window + 1)):\n",
    "            temp=[]\n",
    "            for j in range(window+1):\n",
    "                if j == window:\n",
    "                    y_data.append(input_dict[usr][i+j])\n",
    "                else: \n",
    "                    temp.append(input_dict[usr][i+j])\n",
    "            X_data.append(temp)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data = np.array(X_data)\n",
    "y_data = np.array(y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 1, 3, 1])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_size=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# result = model.evaluate(x_test_pad, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Accuracy: {0:.2%}\".format(result[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=num_loc_time+1,\n",
    "                    output_dim=embedding_size,\n",
    "                    input_length=window,\n",
    "                    name='layer_embedding'))\n",
    "\n",
    "# model.add(GRU(128, return_sequences=True))  # returns a sequence of vectors of dimension 32\n",
    "# model.add(LSTM(64, return_sequences=True)) \n",
    "model.add(LSTM(128))  # return a single vector of dimension 32\n",
    "model.add(Dense(num_loc_time, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=Adam(lr=0.01),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# # Generate dummy training data\n",
    "# x_train = np.random.random((1000, timesteps, data_dim))\n",
    "# y_train = np.random.random((1000, num_classes))\n",
    "\n",
    "# Generate dummy validation data\n",
    "# x_val = np.random.random((100, timesteps, data_dim))\n",
    "# y_val = np.random.random((100, num_classes))\n",
    "\n",
    "# model.fit(X_data, y_data, epochs=2, batch_size=64, verbose=2)\n",
    "\n",
    "# model.fit(x_train, y_train,\n",
    "#           batch_size=64, epochs=5,\n",
    "#           validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded = to_categorical(y_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1837384 samples, validate on 37498 samples\n",
      "Epoch 1/50\n",
      "  54080/1837384 [..............................] - ETA: 26:03 - loss: 2.7886 - acc: 0.3478"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-494f25649b98>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.02\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1637\u001b[0m           \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1638\u001b[0m           \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1639\u001b[0;31m           validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1640\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1641\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    213\u001b[0m           \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 215\u001b[0;31m         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    216\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m           \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2984\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2985\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 2986\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   2987\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2988\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(X_data, encoded, validation_split=0.02, epochs=50, batch_size=64, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_loc_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2086250, 2)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
