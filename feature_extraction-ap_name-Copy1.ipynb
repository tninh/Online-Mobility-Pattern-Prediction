{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import defaultdict, Counter\n",
    "import datetime\n",
    "# from pykovy.src.pykovy import chain\n",
    "# import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from time import time\n",
    "\n",
    "import math\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.python.keras.models import Sequential, Model\n",
    "from tensorflow.python.keras.layers import Dense, GRU, Embedding, LSTM, Flatten, Reshape, Input, BatchNormalization, Bidirectional\n",
    "from tensorflow.python.keras.optimizers import Adam\n",
    "# from tensorflow.python.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.python.keras.utils import to_categorical\n",
    "from tensorflow.python.keras.layers import add, concatenate\n",
    "from tensorflow.python.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "print('after import')\n",
    "\n",
    "# import os\n",
    "# os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "# config = tf.ConfigProto()\n",
    "# config.gpu_options.allow_growth = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./all_data.csv')\n",
    "df = df[['Client Username', 'Association Time', 'AP Name', 'Session Duration', 'Client MAC Address']]\n",
    "df = df.assign(id=(df['Client Username'] + '_' + df['Client MAC Address']).astype('category').cat.codes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['Client Username', 'Client MAC Address'], axis=1)\n",
    "df.rename(columns={'id':'Client Username'}, inplace=True)\n",
    "df = df[['Client Username', 'Association Time', 'AP Name', 'Session Duration']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# recode map location\n",
    "ap_dict = {}\n",
    "count = 0\n",
    "for i in df['AP Name'].unique():\n",
    "    ap_dict[i] = count\n",
    "    count += 1\n",
    "df['AP Name'] = df['AP Name'].map(ap_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def timer(func):\n",
    "    # this part is for timer ignore\n",
    "    def wrapper(*arg):\n",
    "        before = time()\n",
    "        rv = func(*arg)\n",
    "        after = time()\n",
    "        print('Elapsed: ', after-before)\n",
    "        return rv\n",
    "    return wrapper\n",
    "\n",
    "def convertMonth(month):\n",
    "    if month == 'Jan': return 1\n",
    "    elif month == 'Feb': return 2\n",
    "    elif month == 'Mar': return 3\n",
    "    elif month == 'Apr': return 4\n",
    "    elif month == 'May': return 5\n",
    "    elif month == 'Jun': return 6\n",
    "    elif month == 'Jul': return 7\n",
    "    elif month == 'Aug': return 8\n",
    "    elif month == 'Sep': return 9\n",
    "    elif month == 'Oct': return 10\n",
    "    elif month == 'Nov': return 11\n",
    "    elif month == 'Dec': return 12\n",
    "    else: print('error input is not correct')\n",
    "        \n",
    "def convert_to_timeslot(duration):\n",
    "    temp = duration.split()\n",
    "    if len(temp) == 2: sess_duration = int(temp[0])\n",
    "    elif len(temp) == 4: sess_duration = int(temp[0]) * 60 + int(temp[2])\n",
    "    elif len(temp) == 6: sess_duration = (int(temp[0]) * 60 + int(temp[2])) * 60 + int(temp[4])\n",
    "    else: print('error')\n",
    "    return datetime.timedelta(seconds=sess_duration)\n",
    "\n",
    "def convert_to_datetime(time):\n",
    "    temp = time.split()\n",
    "    d_time = datetime.datetime(year=int(temp[5]), month=convertMonth(temp[1]), day=int(temp[2]), hour=int(temp[3].split(':')[0]), minute=int(temp[3].split(':')[1]), second=int(temp[3].split(':')[2]))\n",
    "    return d_time\n",
    "\n",
    "# data_list has same number of row as df.\n",
    "# Each row [userid, map_loc, associate_time, associate_time+sess_dur, sess_dur].\n",
    "def create_data_list(df):\n",
    "    np_df = df.values\n",
    "    data_list = []\n",
    "    c=0\n",
    "    for i in range(np_df.shape[0]):\n",
    "        if c%500000 == 0:\n",
    "            print(c)\n",
    "        temp = np_df[i]\n",
    "#         sess = convert_to_timeslot(df.iloc[i,3])\n",
    "#         s_time = convert_to_datetime(df.iloc[i,1])\n",
    "#         e_time = s_time + sess\n",
    "#         data_list.append([df.iloc[i,0], df.iloc[i,2], s_time, e_time, sess])\n",
    "        sess = convert_to_timeslot(temp[3])\n",
    "        s_time = convert_to_datetime(temp[1])\n",
    "        e_time = s_time + sess\n",
    "        data_list.append([temp[0], temp[2], s_time, e_time, sess])\n",
    "        c+=1\n",
    "        \n",
    "    data_list = sorted(data_list, key=lambda element: (element[0], element[2]))\n",
    "    data_list1 = sorted(data_list, key=lambda element: (element[2]))\n",
    "    first = data_list1[0][2]\n",
    "    last = data_list1[-1][2]\n",
    "    return data_list, first, last\n",
    "\n",
    "# add up the session duration when the previous row has the same userid and location. \n",
    "# (this happen when you disconnect from the ap and reconnect again or your wifi session expire, etc.)\n",
    "def preprocess_data_list(data_list):\n",
    "    for i in reversed(range(1, len(data_list))):\n",
    "        ts_cur = data_list[i][2]\n",
    "        ts_prev = data_list[i-1][2]\n",
    "        if data_list[i][0] == data_list[i-1][0] and data_list[i][1] == data_list[i-1][1] and ts_cur.day == ts_prev.day and ts_cur.month == ts_prev.month:\n",
    "#             if data_list[i][2] - data_list[i-1][3] <= datetime.timedelta(hours=2):\n",
    "            data_list[i-1][4] += data_list[i][4]\n",
    "#             else: print(i)\n",
    "    # loop each row, remove the next concecutive rows has the same userid and map_loc with the current row.\n",
    "    # Because they are useless now\n",
    "    final_data_list = []\n",
    "    i = 0\n",
    "    while i < len(data_list)-1:\n",
    "        ts_cur = data_list[i][2]\n",
    "        ts_next = data_list[i+1][2]\n",
    "        if data_list[i][0] == data_list[i+1][0] and data_list[i][1] == data_list[i+1][1] and ts_cur.day == ts_next.day and ts_cur.month == ts_next.month:\n",
    "            final_data_list.append(data_list[i])\n",
    "            c = 2\n",
    "            while i+c < len(data_list) and data_list[i][0] == data_list[i+c][0] and data_list[i][1] == data_list[i+c][1] and ts_cur.day == ts_next.day and ts_cur.month == ts_next.month:\n",
    "                c += 1\n",
    "            i += c\n",
    "\n",
    "        else:\n",
    "            final_data_list.append(data_list[i])\n",
    "            i += 1\n",
    "\n",
    "    if not (final_data_list[-1][0] == data_list[-1][0] and final_data_list[-1][1] == data_list[-1][1]):\n",
    "        final_data_list.append(data_list[-1])\n",
    "\n",
    "    return final_data_list\n",
    "\n",
    "\n",
    "# user_dict's key are each userid and value is a list of all rows of each user in final_data_list\n",
    "def create_user_dict(final_data_list):\n",
    "    user_dict = defaultdict(list)\n",
    "    for row in final_data_list:\n",
    "        user_dict[row[0]].append([row[2], row[1], row[4]])\n",
    "\n",
    "    return user_dict\n",
    "\n",
    "# \n",
    "def remove_jitter(final_data_list):\n",
    "    res = [final_data_list[0]]\n",
    "    i = 1\n",
    "    mem = 0\n",
    "    while i < len(final_data_list):\n",
    "        cur_usrid = final_data_list[i][0]\n",
    "        cur_loc = final_data_list[i][1]\n",
    "        cur_sess = final_data_list[i][4]\n",
    "        cur_end_time = final_data_list[i][2] + final_data_list[i][4]\n",
    "        cont_time = final_data_list[i][2] - (res[-1][2] + res[-1][4]) <= datetime.timedelta(minutes=1)\n",
    "        if cur_usrid == res[-1][0] and cur_sess <= datetime.timedelta(minutes=1) and cont_time:\n",
    "\n",
    "\n",
    "            if cur_loc != res[-1][1] and mem == 0:\n",
    "                mem = i\n",
    "\n",
    "            elif cur_loc == res[-1][1]:\n",
    "                \n",
    "#                 print(i, cur_loc, cur_end_time, res[-1][1], res[-1][2])\n",
    "\n",
    "#                 print(cur_end_time - res[-1][2])\n",
    "                res[-1][4] = cur_end_time - res[-1][2]\n",
    "#                 print(res[-1][4])\n",
    "                mem=0\n",
    "                \n",
    "            else: pass\n",
    "        elif cur_usrid == res[-1][0] and cur_sess <= datetime.timedelta(minutes=1) and not cont_time:\n",
    "            if cur_loc != res[-1][1] and mem == 0:\n",
    "                res.append(final_data_list[i])\n",
    "\n",
    "            elif cur_loc == res[-1][1]:\n",
    "                res[-1][4] = cur_end_time - res[-1][2]\n",
    "                mem=0\n",
    "                \n",
    "            else:                 \n",
    "                for j in range(mem, i):\n",
    "                    res.append(final_data_list[j])\n",
    "                res.append(final_data_list[i])\n",
    "                mem=0\n",
    "        else:\n",
    "            if mem != 0:\n",
    "                for j in range(mem, i):\n",
    "                    res.append(final_data_list[j])\n",
    "                res.append(final_data_list[i])\n",
    "                mem=0\n",
    "            else: res.append(final_data_list[i])\n",
    "        \n",
    "        i+=1\n",
    "\n",
    "    return res\n",
    "\n",
    "@timer\n",
    "def preprocess_and_create_user_dict(df):\n",
    "    data_list, start_ts, end_ts= create_data_list(df)\n",
    "    final_data_list = preprocess_data_list(data_list)\n",
    "    print(len(final_data_list), len(data_list))\n",
    "    final_data_list = remove_jitter(final_data_list)\n",
    "    print(len(final_data_list), len(data_list))\n",
    "    user_dict = create_user_dict(final_data_list)\n",
    "    return user_dict, start_ts, end_ts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "500000\n",
      "1000000\n",
      "1500000\n",
      "2000000\n",
      "2500000\n",
      "3000000\n",
      "3500000\n",
      "4000000\n",
      "4500000\n",
      "5000000\n",
      "5500000\n",
      "6000000\n",
      "4061485 6114987\n",
      "4061202 6114987\n",
      "Elapsed:  97.63698029518127\n"
     ]
    }
   ],
   "source": [
    "user_dict, start_ts, end_ts = preprocess_and_create_user_dict(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [i for i in user_dict if len(user_dict[i]) < 20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = map(user_dict.pop, a)\n",
    "for i in range(len(a)):\n",
    "    try:\n",
    "        next(t)\n",
    "    except:\n",
    "        print('fail')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_timeslot1(d_time):\n",
    "    slot = (d_time.hour * 60 + d_time.minute)/5\n",
    "    return int(slot) if slot < int(slot) + 0.5 else int(slot) + 1\n",
    "\n",
    "def create_data(user_dict):\n",
    "    input_data = []\n",
    "    c = 0\n",
    "    for usr in user_dict:\n",
    "        c+=1\n",
    "        if c % 5000 == 0: print(c)\n",
    "        for j in range(len(user_dict[usr] )-1):\n",
    "            loc = user_dict[usr][j][1]\n",
    "            input_data.append([usr, user_dict[usr][j][0].weekday(), loc])\n",
    "            \n",
    "    return input_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000\n",
      "10000\n",
      "15000\n",
      "20000\n",
      "25000\n",
      "30000\n"
     ]
    }
   ],
   "source": [
    "input_data = create_data(user_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame(data=input_data, columns=['userID', 'weekday', 'location'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_dict_time_loc = {}\n",
    "num_loc_time = 1\n",
    "for i in df1['location'].unique():\n",
    "    map_dict_time_loc[i] = num_loc_time\n",
    "    num_loc_time += 1\n",
    "df1['location'] = df1['location'].map(map_dict_time_loc)\n",
    "np_df1 = df1.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "500000\n",
      "1000000\n",
      "1500000\n",
      "2000000\n",
      "2500000\n",
      "3000000\n",
      "3500000\n"
     ]
    }
   ],
   "source": [
    "input_dict = defaultdict(list)\n",
    "week_dict = defaultdict(list)\n",
    "for i in range(np_df1.shape[0]):\n",
    "    if i % 500000 == 0: print(i)\n",
    "    temp = np_df1[i]\n",
    "    input_dict[temp[0]].append(temp[2])\n",
    "    week_dict[temp[0]].append(temp[1])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data = []\n",
    "y_data = []\n",
    "usr_data = []\n",
    "week_data = []\n",
    "window = 8\n",
    "\n",
    "for usr in input_dict:\n",
    "#     if usr != 29: continue \n",
    "    size = len(input_dict[usr])\n",
    "    \n",
    "    if size == 0: continue\n",
    "    elif size <= window:\n",
    "        temp = []\n",
    "        for _ in range(window - size):\n",
    "            temp.append(0)\n",
    "        for i in range(size-1):\n",
    "            temp.append(input_dict[usr][i])\n",
    "        week_data.append(week_dict[usr][-2])\n",
    "        X_data.append(temp)\n",
    "        usr_data.append(usr)\n",
    "        try:\n",
    "            y_data.append(input_dict[usr][-1])\n",
    "        except:\n",
    "            print(usr)\n",
    "    else:\n",
    "        for i in range(size - (window + 1)):\n",
    "            temp=[]\n",
    "            for j in range(window+1):\n",
    "                if j == window:\n",
    "                    y_data.append(input_dict[usr][i+j])\n",
    "                elif j == window - 1:\n",
    "                    temp.append(input_dict[usr][i+j])\n",
    "                    week_data.append(week_dict[usr][i+j])\n",
    "                else:\n",
    "                    temp.append(input_dict[usr][i+j])\n",
    " \n",
    "            X_data.append(temp)\n",
    "            usr_data.append(usr)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data = np.array(X_data)\n",
    "y_data = np.array(y_data)\n",
    "usr_data = np.array(usr_data)\n",
    "usr_data1 = np.zeros(len(usr_data))\n",
    "week_data = np.array(week_data)\n",
    "# reid user\n",
    "temp = {}\n",
    "count = -1\n",
    "for i in range(len(usr_data)):\n",
    "    if usr_data[i] not in temp:\n",
    "        count += 1\n",
    "        temp[usr_data[i]] = count\n",
    "        usr_data1[i] = count\n",
    "    else:\n",
    "        usr_data1[i] = temp[usr_data[i]]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = len(set(usr_data))\n",
    "usr_data = usr_data1.reshape(usr_data1.shape[0], 1)\n",
    "week_data = week_data.reshape(week_data.shape[0], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_size = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modela = Sequential()\n",
    "modela.add(Embedding(input_dim=num_loc_time,\n",
    "                    output_dim=embedding_size,\n",
    "                    input_length=window,\n",
    "                    name='layer_embedding'))\n",
    "\n",
    "# modela.add(Bidirectional(LSTM(128, return_sequences=True)))\n",
    "modela.add(Bidirectional(LSTM(64, return_sequences=True)))\n",
    "modela.add(Bidirectional(LSTM(32)))\n",
    "\n",
    "# modela.add(Dense(500, activation='relu'))\n",
    "modela.add(Dense(200, activation='relu'))\n",
    "\n",
    "\n",
    "modelb = Sequential()\n",
    "modelb.add(Embedding(input_dim=a,\n",
    "                    output_dim=20,\n",
    "                    input_length=1,\n",
    "                    name='layer_embedding1'))\n",
    "\n",
    "modelb.add(Dense(100, activation='relu'))\n",
    "modelb.add(Flatten())\n",
    "\n",
    "modelc = Sequential()\n",
    "modelc.add(Dense(5, activation='relu', input_shape=(7,)))\n",
    "modelc.add(Flatten())\n",
    "\n",
    "\n",
    "merged_output = concatenate([modela.output, modelb.output, modelc.output])\n",
    "model_combined = Sequential()\n",
    "\n",
    "model_combined.add(Dense(num_loc_time, activation='softmax'))\n",
    "\n",
    "final_model = Model([modela.input, modelb.input, modelc.input], model_combined(merged_output))\n",
    "final_model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=Adam(lr=0.01),\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_data1 = to_categorical(y_data)\n",
    "week_data1 = to_categorical(week_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath=\"weights-improvement-{epoch:02d}-{val_acc:.2f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "callbacks_list = [checkpoint]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/011816337/.local/lib/python3.5/site-packages/tensorflow/python/ops/gradients_impl.py:112: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2957725 samples, validate on 328637 samples\n",
      "Epoch 1/20\n",
      "2957725/2957725 [==============================] - 941s 318us/step - loss: 4.0132 - acc: 0.2280 - val_loss: 4.1209 - val_acc: 0.1943\n",
      "Epoch 2/20\n",
      "2957725/2957725 [==============================] - 935s 316us/step - loss: 3.7364 - acc: 0.2700 - val_loss: 4.0896 - val_acc: 0.2044\n",
      "Epoch 3/20\n",
      " 473344/2957725 [===>..........................] - ETA: 12:35 - loss: 3.6922 - acc: 0.2752"
     ]
    }
   ],
   "source": [
    "final_model.fit([X_data, usr_data, week_data1], y_data1, validation_split=0.1, epochs=20, batch_size=256, callbacks=callbacks_list, verbose=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
